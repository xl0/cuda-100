{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 - RGB blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda version: 12.8.0\n",
      "Device:\tNVIDIA GeForce RTX 3080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "cuda.init()\n",
    "\n",
    "device = cuda.Device(0)\n",
    "\n",
    "print(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\n",
    "print(f\"Device:\\t{device.name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[day_03_blurry.cu](https://github.com/xl0/cuda-100/blob/master/nbs/day_04_matmaul.cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "::: {.code-block}\n",
      "```\n",
      "#include <stdint.h>\n",
      "#include <stdio.h>\n",
      "\n",
      "__global__ void matmul_f32(float *m1, float *m2, float *res,\n",
      "    uint32_t out_shape_0,\n",
      "    uint32_t out_shape_1,\n",
      "    uint32_t inner_dim,\n",
      "    uint32_t ) {\n",
      "\n",
      "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
      "\n",
      "    int m1_width = inner_dim;\n",
      "    int m2_width = out_shape_1;\n",
      "\n",
      "    double out;\n",
      "    if (x < out_shape_1 && y < out_shape_0) {\n",
      "        out = 0;\n",
      "        for (int i = 0; i < inner_dim; i++) {\n",
      "            out += m1[y*m1_width + i] * m2[i*m2_width + x];\n",
      "        }\n",
      "        res[y*out_shape_1 + x] = out;\n",
      "    }\n",
      "\n",
      "\n",
      "\n",
      "    // if (x < w && y < h) {\n",
      "    //     int idx = (y * w + x);\n",
      "\n",
      "    //     for (int ch = 0; ch < 3; ch++) {\n",
      "    //         uint32_t v = 0;\n",
      "    //         for (int j = -blur; j <= (int)blur; j++) {\n",
      "    //             for (int i = -blur; i <= (int)blur; i++) {\n",
      "    //                 if (y + j >= 0   &&\n",
      "    //                     y + j < h    &&\n",
      "    //                     x + i >= 0   &&\n",
      "    //                     x + i < w) {\n",
      "    //                         v += in[ ((y + j) * w + x + i)*3 + ch];\n",
      "    //                     }\n",
      "    //             }\n",
      "    //         }\n",
      "\n",
      "    //         out[idx*3+ch] = (uint8_t)(v / ((2*blur + 1) * (2*blur + 1)));\n",
      "    //     }\n",
      "    // }\n",
      "}\n",
      "\n",
      "\n",
      "```\n",
      ":::\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|output: asis\n",
    "#|echo: false\n",
    "\n",
    "c_code = Path('day_04_matmul.cu').read_text()\n",
    "print(f'''\n",
    "::: {{.code-block}}\n",
    "```\n",
    "{c_code}\n",
    "```\n",
    ":::\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lovely_numpy import Lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array[100, 300] f32 n=30000 (0.1Mb) x∈[-81.072, 54.578] μ=-0.081 σ=14.183"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.random.randn(100, 200).astype(np.float32)\n",
    "m2 = np.random.randn(200, 300).astype(np.float32)\n",
    "\n",
    "np_res = np.matmul(m1, m2)\n",
    "Lo(np_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: (10, 4, 1)\n",
      "Block size: (32, 32, 1)\n",
      "Restul dimensions: 100x300\n",
      "Total threads: 40960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array[100, 300] f32 n=30000 (0.1Mb) x∈[-81.073, 54.578] μ=-0.081 σ=14.183"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLOCK_SIZE_X = 32\n",
    "BLOCK_SIZE_Y = 32\n",
    "\n",
    "assert(len(m1.shape) == 2)\n",
    "assert(len(m2.shape) == 2)\n",
    "assert(m1.shape[1] == m2.shape[0])\n",
    "\n",
    "out_shape = (m1.shape[0], m2.shape[1])\n",
    "\n",
    "try:\n",
    "    ctx = device.make_context()\n",
    "\n",
    "    mod = SourceModule(Path(\"day_04_matmul.cu\").read_text(),\n",
    "        options=[\n",
    "            '-Xcompiler', '-Wall',\n",
    "            '-Xcompiler', '-Wextra',\n",
    "            '-Xcompiler', '-Wsign-conversion',\n",
    "            '-Xcompiler', '-Wcast-qual',\n",
    "            '-Xcompiler', '-Wunused-parameter',\n",
    "            '-Xcompiler', '-Wdouble-promotion',\n",
    "            '-Xcompiler', '-Wformat=2',\n",
    "            '-Xcompiler', '-Wfloat-equal',\n",
    "            '-Xcompiler', '-Wshadow'\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    matmul_f32 = mod.get_function(\"matmul_f32\")\n",
    "\n",
    "    gpu_m1 = cuda.mem_alloc_like(m1)\n",
    "    gpu_m2 = cuda.mem_alloc_like(m2)\n",
    "\n",
    "    res = np.empty(out_shape, dtype=np.float32)\n",
    "\n",
    "    gpu_res = cuda.mem_alloc_like(res)\n",
    "\n",
    "\n",
    "    cuda.memcpy_htod(gpu_m1, m1)\n",
    "    cuda.memcpy_htod(gpu_m2, m2)\n",
    "\n",
    "    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n",
    "    grid_size = (\n",
    "        ((out_shape[1] + BLOCK_SIZE_X - 1) // BLOCK_SIZE_X),\n",
    "        ((out_shape[0] + BLOCK_SIZE_Y - 1) // BLOCK_SIZE_Y),\n",
    "        1\n",
    "    )\n",
    "\n",
    "    print(f\"Grid size: {grid_size}\")\n",
    "    print(f\"Block size: {block_size}\")\n",
    "    print(f\"Restul dimensions: {out_shape[0]}x{out_shape[1]}\")\n",
    "    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n",
    "\n",
    "    ctx.synchronize()\n",
    "\n",
    "    matmul_f32(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n",
    "\n",
    "    ctx.synchronize()\n",
    "\n",
    "    cuda.memcpy_dtoh(res, gpu_res)\n",
    "    ctx.synchronize()\n",
    "\n",
    "\n",
    "finally:\n",
    "    ctx.pop()\n",
    "    ctx.detach()\n",
    "\n",
    "Lo(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(-1.1215224), np.float32(-0.32335585))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0,1],m2[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(res, np_res).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAABrCAYAAAD5Ln4JAAAALHRFWHRTb2Z0d2FyZQBNYXRwbG90bGliLCBodHRwczovL21hdHBsb3RsaWIub3JnL5Di+PEAAAAJcEhZcwAAD2EAAA9hAag/p2kAAAYuSURBVHic7d3NtRs3DIZhKef2cbfuwT146SKzTA/pIVtXcr1IdKRIMxqSQwIfgPdZJY5zhr8gSI6k69fX19cFAOK7/uFdAgCY5eP2D9fr1bMcANDteYP58fgvv/75ZVKIH99/Xv76+0+TZ/VSLhuAu89vny9/5rLlvAWMH99/ejz+LYJZTYpjsUf08s9yvV0KXK9XswwN8ZC5wtrRmPv89vm85eRSAG2qBLPWTCdSRjSzrJb1HhlzMhkaGYCv6u1fvf4RSWdoKwZTpFXUW/XJfFR/xpKfnraXydCAyEYyPLLCc7YyNAIaUEyWQCq35SSNh5oKYzJDMNtjEtD2BknmhkVMK8dkS7AcDagVAnEL+S1nlvQYmK13bmSbS3JbzhaZOiAzxQxBsUxb9sp5VP7euVFhLslnaEAU2TIgdS4ZWoRVMkIZz6pQR29bwYx2tzUU0Ho+HhJhxYpQxrMi1TFTEDjb7pnawgJbzsWiBHX4Ypz048VaAGmEvOXEtpVbEbY5Y6K2W9RybyFD28EWANBGhtaBYNYn0yrfy7LuZ54V7VMII889naGRyQA+qs+9JRla5QZ9J2PGkrFOR5TrzNx7xRkadlXPAEbRbjaWn6EprWZKZYlgq71aJiXt/Ipg5ocMzYjiqq1YJviKNCa45XxjdaYxc5DMKqvlwLXI5LaekfFXnFbyDGYz+mA4Q/OM5JFWEcTEGNPHR5/QjYkNVWw5F8u4bSGY3Sn3r3LZLL0ENBpmHJM/t1n9u2KOrR57UeKCyZaTbcs+2gYY47bljDphLValqG0TReVvJVEv3wpcCmApMlCctTeGuBSAOYVgFuXbMNSo1KVnDL1kaJlX1Mx1A6ppytAeJ7xnhI54E6RCZWWtiLb3xS0npqKvYYVbzoKsMwalvs6cLWWu2+UyXj9uOQGExC0nMCB7NpSJS0CzGiAMRMzQu42OMu6ilLMHW87JbofiHI7bo81r4euDUBKBrl2ktuIM7T/Z3q/zeL53PXrcJmikMnuJEsz2kKE52VoJI62OgLdSv/qkbitwEczgJcvcDZ+hkdUANUmfoY2uEIrBLMtqhxgYb3duAS1zJygG2Ywyj6EejLc7t4D23Al0yhwrJrlq4Jg9ZlTriXbhz9Cy4mwQeG/oDK3ie0sKCGZAv8OANmtiWU5QgucctGMdyn3dUza2nABCMn9tQznqj8pYJ8DSmTl09P8uDWgZz4FG6kQQ1JCpHyKfbe/NoZayHM0/tpwAQpL+pACgxCNzyZRBeiGgARs8jktUj2h6A+3W37cK1hJbTl4iBdBLdsvZGsxIyYG6Wua/REBrRRa3BgtFDtn7sWX+Nwe07I1VGQtFDpn7sTX+NH+WM3NjKZi9YHgvQN7PxzqjfXtmTLTGH4lLgSNcGgB4JnspcIRgpq9KRlalnlGFCGjwNeMjKbPtlWl1wGFx1RZiywlgjMJxzaoydG85Sa9jo/+gkDlbluFtQPOO7KMsJ7Jy0Nj6IWNgpTPfpDHD8jO0x4qsrpTHKyaRgr5FWQmaeczsS6t5UuIMTeEcAcC+kTka9rWNswhmuZEVauu5JT/blyUCmhXliaVctrNYsDSNHAGd7ctwAU15YipPLOWy3Sj3LV4d9ZfHmAsX0CJMTPyrJUA9/h36Npaj/vJYoMIFNMTR8tqIVxCrkA1619Gjb0vccgLIp+wt556Vvw+IO9oKvUbHTNgMjXfLgPWU59lWhhY2oAGoLcSWk+0JbbBS9rbNXr8jZGgALpeL9vZyS4gMbYbqq1Rm9O06kYLZnuGApjywMnQM7nj59hzluTobW07gpGhbtVWs26HMllNZ72pZaXVVpPh7CitZ/NRcazlGykKGZmRv9WJ1B8aQoTnaC1oEM7S4ZSseGfvMZ64uPxlaQGR1UGcxRsnQklg1ULzO6zgnfBW9TbwWXDI0ACGFz9BGVq3oKx3OUej/5zIolCkrMrTEOGuzQ1vbk83Qoq1YUcrLBLPrq5VtHWW8KSBD62S5ErPqA/tkM7RIVgSYvRWYVT833imbjwwNLzwzwzPPJqPVNrt/+MZapEMQq2vqllMx3VSg1C5KZVmFYIZH/8vQACCS5wztY+c/AEA43HICSIOABiCN3yMBFSd0A3qWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<lovely_numpy.repr_chans.ChanProxy>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lo(np.isclose(res, np_res)).chans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like matmul is very succeptible to numerical instability.\n",
    "> Since we are adding numbers to the accumulator over and over, if it accumulated value gets large enough,\n",
    "> it will lose precision to correctly accumulate small values. If it then gets a large negative update and becomes\n",
    "> small again, those errors will become significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
