[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "100 days of CUDA",
    "section": "",
    "text": "Installation instructions (how I do)\n\nCreate a mamba environment\nmamba install python=3.12 (pycuda do not work in 3.13 yet)\nmamba cuda\npip install pycuda\n\n\n\nProgress\n\nDay 0 playing with PyCUDA\nDay 1 playing with NVCC, vector addition\nDay 2 RGB 2 gray\nDay 3 RGB blur\nDay 4 Naive matmul+exercises\nDay 5 Matrix-vecor multiplication\nDay 6 Tiled matmul\nDay 7 Tiled matmul - experiments\nDay 8 Tiled matmul - thread coarsening\nDay 9 Naive conv2d with arbitrary number of channels\nDay 10 faster conv2d\nDay 11 conv2d with shared memory\nDay 12 conv2d with shared memory + halo\n\nSome CUDA (or C) quirks to note:\n\n\nSigned-unsigned comparison is dumb\nuint32_t a =  1;\nint32_t  j = -1;\nj &gt;= a == true\nj +  a == 0\nSomehow this is how type casting works in C. :/\n\n\nBenchmarking\nRun this script before benchmarking to lock gpu/mem frequence and hopefully avoid thermal throttling and unstable timings\n\nsudo nvidia-smi -pm 1 # Set GPU to persistent mode\nsleep 2\n\nsudo nvidia-smi -lgc 1000,1000 # Lock clocks to prevent frequency scaling\nsudo nvidia-smi -lmc 5000,5000 # Memory clock\nsudo nvidia-smi --auto-boost-default=0  # Disable auto-boost",
    "crumbs": [
      "100 days of CUDA"
    ]
  },
  {
    "objectID": "day_10_conv2d-experiments.html",
    "href": "day_10_conv2d-experiments.html",
    "title": "Day 10 - Improving Conv2d performance",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom math import prod\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\n\nfrom lovely_numpy import Lo\nfrom lovely_tensors import monkey_patch; monkey_patch()\nfrom torch import Tensor\nfrom torch.nn.functional import conv2d\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file_naive=\"kernels/conv2d/conv2d_naive.cu\"\n\n\nkernels/conv2d/conv2d_naive.cu\nThe first implementation from the previous day\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n#include \"conv2d-helpers.h\"\n\n/* 2D convolution, with padding to valid shape. Channel-first */\n__global__ void conv2d_pad(float *in,\n                           float *out,\n                           float *filter,\n                           int h,\n                           int w,\n                           int in_channels,\n                           int out_channels,\n                           int filter_size /* Must be an odd number */,\n                           float pad) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int filter_r = (filter_size - 1) / 2;\n\n\n    // In and Out data dimensions:\n    // 0 - channel\n    // 1 - height\n    // 2 - width\n\n    // Filter dimensions:\n    // 0 - out channels\n    // 1 - in channels\n    // 2 - height\n    // 3 - width\n\n    if (x &gt;= w || y &gt;= h) return;\n\n#ifdef DEBUG\n    if (x == 0 && y == 0) {\n        PRINT_INPUTS();\n    }\n#endif\n\n\n    // Loop over the output channels\n    for (int out_c = 0; out_c &lt; out_channels; out_c++) {\n        ACCUM_DTYPE R = 0;\n\n        // Pointer to the 2d slice of the output\n        float *sub_output = out + out_c * w * h;\n\n        // Loop over the input channels\n        for (int in_c = 0; in_c &lt; in_channels; in_c++) {\n            // Pointer to the 2d slice of the filter that corresponds to the active input and output\n            // channels\n            float *sub_filter = filter + (filter_size * filter_size * in_channels * out_c) +\n                                (filter_size * filter_size * in_c);\n            // Pinter to the current channel in the input\n            float *sub_input = in + (w * h * in_c);\n\n            // Apply the filter to the input or the pad value for outside indices.\n            for (int filter_y = 0; filter_y &lt; filter_size; filter_y++) {\n                for (int filter_x = 0; filter_x &lt; filter_size; filter_x++) {\n                    float v = pad;\n                    int input_x = x - filter_r + filter_x;\n                    int input_y = y - filter_r + filter_y;\n\n                    if (input_x &gt;= 0 && input_x &lt; w && input_y &gt;= 0 && input_y &lt; h) {\n                        v = sub_input[input_y * w + input_x];\n                    }\n                    R += v * sub_filter[filter_y * filter_size + filter_x];\n                }\n            }\n        }\n        sub_output[y * w + x] = R;\n    }\n}\n\n\ncu_file_z_out=\"kernels/conv2d/conv2d-z-out.cu\"\n\n\n\nkernels/conv2d/conv2d-z-out.cu\nThis implementation uses separate blocks per output channel\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n#include \"conv2d-helpers.h\"\n\n// This version uses the z grid dimensions for out channels\n// This means each thread has to calculate only one output channel\n__global__ void conv2d_pad_z_out(float *in,\n                                 float *out,\n                                 float *filter,\n                                 int h,\n                                 int w,\n                                 int in_channels,\n                                 int out_channels,\n                                 int filter_size /* Must be an odd number */,\n                                 float pad) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int out_ch = blockIdx.z;\n\n    int filter_r = (filter_size - 1) / 2;\n\n    // In and Out data dimensions:\n    // 0 - channel\n    // 1 - height\n    // 2 - width\n\n    // Filter dimensions:\n    // 0 - out channels\n    // 1 - in channels\n    // 2 - height\n    // 3 - width\n\n    if (x &gt;= w || y &gt;= h) return;\n\n#ifdef DEBUG\n    if (x == 0 && y == 0) PRINT_INPUTS();\n#endif\n\n    // Loop over the output channels\n\n    ACCUM_DTYPE R = 0;\n\n    // // Pointer to the 2d slice of the output\n    float *sub_output = out + out_ch * w * h;\n    // Loop over the input channels\n    for (int in_c = 0; in_c &lt; in_channels; in_c++) {\n        // Pointer to the 2d slice of the filter that corresponds to the active input and output\n        // channels\n        float *sub_filter = filter + (filter_size * filter_size * in_channels * out_ch) +\n                            (filter_size * filter_size * in_c);\n        // Pinter to the current channel in the input\n        float *sub_input = in + (w * h * in_c);\n\n        // Apply the filter to the input or the pad value for outside indices.\n        for (int filter_y = 0; filter_y &lt; filter_size; filter_y++) {\n            for (int filter_x = 0; filter_x &lt; filter_size; filter_x++) {\n                float v = pad;\n                int input_x = x - filter_r + filter_x;\n                int input_y = y - filter_r + filter_y;\n\n                if (input_x &gt;= 0 && input_x &lt; w && input_y &gt;= 0 && input_y &lt; h) {\n                    v = sub_input[input_y * w + input_x];\n                }\n                R += v * sub_filter[filter_y * filter_size + filter_x];\n            }\n        }\n    }\n    sub_output[y * w + x] = R;\n}\n\n\ndef benchmark_conv2d_pad(ctx, kernel, input, filter, pad, block_size, grid_size, repeat=10, warmup=True):\n    # input, channel-first\n    # - Channel\n    # - Height\n    # - Width\n    assert len(input.shape) == 3\n\n    # Filter shape should be\n    # - Out channels\n    # - In  channels\n    # - Height\n    # - Width\n    assert len(filter.shape) == 4\n\n    in_ch, h, w = input.shape\n    out_ch, in_ch2, fh, fw = filter.shape\n\n    assert fh == fw, f\"Only square filters supported, got shape={filter.shape}\"\n\n    assert in_ch == in_ch2\n\n    out_shape = (out_ch, h, w)\n\n    gpu_input = cuda.mem_alloc_like(input)\n    gpu_filter = cuda.mem_alloc_like(filter)\n\n    out = np.empty(out_shape, dtype=np.float32)\n\n    cuda.memcpy_htod(gpu_input, input)\n    cuda.memcpy_htod(gpu_filter, filter)\n    ctx.synchronize()\n\n    timing=0\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n        gpu_out = cuda.mem_alloc_like(out)\n\n        if warmup:\n            kernel(gpu_input, gpu_out, gpu_filter,\n                   np.int32(h),\n                   np.int32(w),\n                   np.int32(in_ch),\n                   np.int32(out_ch),\n                   np.int32(fh),\n                   np.float32(pad),\n                   grid=grid_size,\n                   block=block_size)\n            ctx.synchronize()\n\n        start.record()\n        kernel(gpu_input, gpu_out, gpu_filter,\n               np.int32(h),\n               np.int32(w),\n               np.int32(in_ch),\n               np.int32(out_ch),\n               np.int32(fh),\n               np.float32(pad),\n               grid=grid_size,\n               block=block_size)\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n\n    cuda.memcpy_dtoh(out, gpu_out)\n    return out, timing;\n\n\n\nTest matrix\nSample some random shapes (not too big though) for input/output/channels/filter sizes\n\nin_chan_range = [1, 3, 8, 32, 128, 512]\nout_chan_range = [1, 4, 8, 32, 128, 512]\n\nfilter_size = [1, 3, 5, 9]\n\nimg_size_range = [64, 128, 256, 512, 1024]\n\n# Let's sample from the available options.\nn_samples = 50\n\n\n# Generate all possible combinations\ncombinations = []\nfor in_ch in in_chan_range:\n    for out_ch in out_chan_range:\n        for fs in filter_size:\n            for img_size in img_size_range:\n                    n = in_ch * out_ch * img_size * img_size\n\n                    # Skip combinatoins that are too large\n                    if n &lt; 1024*1024*32*32:\n                        combinations.append((in_ch, out_ch, fs, img_size))\n\nn_samples = min(n_samples, len(combinations))\nsampled_combinations = np.random.choice(len(combinations), size=n_samples, replace=False)\ntest_cases = [combinations[i] for i in sampled_combinations]\n\n\n\nRun the tests\n\nimport warn_options\n\n\ntile_width = 32\n\ndata = []\n\n# test_cases = [(3, 4, 32,32)]\n\nctx = device.make_context()\ntry:\n    mod_naive = SourceModule(\n        Path(cu_file_naive).read_text(),\n        options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\"],\n        include_dirs=[str(Path(cu_file_naive).parent.absolute())]\n        )\n\n    mod_z_out = SourceModule(\n        Path(cu_file_z_out).read_text(),\n        options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\"],\n        include_dirs=[str(Path(cu_file_z_out).parent.absolute())])\n\n\n    kernels = {\n        \"conv2d_pad\": mod_naive.get_function(\"conv2d_pad\"),\n        \"conv2d_pad_z_out\":mod_z_out.get_function(\"conv2d_pad_z_out\"),\n    }\n\n    for tc in tqdm(test_cases):\n        ch_in, ch_out, fs, pixels = tc\n\n        array_in = np.random.randn(ch_in, pixels, pixels).astype(np.float32)\n        filter = np.random.randn(ch_out, ch_in, fs, fs).astype(np.float32)\n\n        torch_out = conv2d(Tensor(array_in), Tensor(filter), padding=\"same\")\n\n        timings = {}\n\n        for kernel_name, kernel in kernels.items():\n\n            block_size = (tile_width,tile_width,1)\n            grid_size = (\n                ((pixels + tile_width - 1) // tile_width),\n                ((pixels + tile_width - 1) // tile_width),\n                ch_out if kernel_name == \"conv2d_pad_z_out\" else 1\n            )\n\n\n            out, timing = benchmark_conv2d_pad(ctx, kernel, array_in, filter, 0, block_size, grid_size, repeat=5, warmup=True)\n\n            if np.isclose(out, torch_out).mean() &lt; 0.8:\n                print(\"### Result mismatch ###\")\n                print(f\"Kernel: {kernel_name}\")\n                print(f\"Input shape: {array_in.shape}\")\n                print(f\"Filter shape: {filter.shape}\")\n                print(f\"Result shape: {(filter.shape[0], array_in.shape[1], array_in.shape[2])}\")\n                print(f\"Grid size: {grid_size}\")\n                print(f\"Block size: {block_size}\")\n                print(f\"Total threads: {prod((*grid_size, *block_size))}\")\n\n            timings[kernel_name] = timing\n\n        data.append({\n            'in_ch': ch_in,\n            'out_ch': ch_out,\n            'filter_size': fs,\n            'img_size': pixels,\n            # 'kernel': kernel_name,\n        } | timings)\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nresults = pd.DataFrame(data)\n\n\n\n\n\n\nTest results\n\n# Sort by conv2d_pad timing\nresults_sorted = results.sort_values(by='conv2d_pad')\n\n# Create a plot comparing the two kernels\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(12, 8))\nsns.set_style(\"whitegrid\")\n\n# Create labels for x-axis that include dimensions\nresults_sorted['dimensions'] = results_sorted.apply(\n    lambda row: f\"{int(row['img_size'])}×{int(row['img_size'])}×{int(row['in_ch'])} -&gt; {int(row['out_ch'])}, f:{int(row['filter_size'])}×{int(row['filter_size'])}\",\n    axis=1\n)\n\n# Melt the dataframe to get it in the right format for seaborn\nmelted_results = pd.melt(\n    results_sorted,\n    id_vars=['in_ch', 'out_ch', 'filter_size', 'img_size', 'dimensions'],\n    value_vars=['conv2d_pad', 'conv2d_pad_z_out'],\n    var_name='kernel',\n    value_name='time'\n)\n\n# Create a barplot with dimensions as x-ticks\nax = sns.barplot(x='dimensions', y='time', hue='kernel', data=melted_results)\n\n# Add labels\nplt.xlabel('Input and Filter Dimensions')\nplt.ylabel('Time (seconds)')\nplt.title('Performance Comparison of conv2d_pad vs conv2d_pad_z_out')\nplt.xticks(rotation=90)\n\n# Add a legend\nplt.legend(title='Kernel')\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\n# Also display the sorted results table\nresults_sorted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nin_ch\nout_ch\nfilter_size\nimg_size\nconv2d_pad\nconv2d_pad_z_out\ndimensions\n\n\n\n\n49\n1\n1\n1\n256\n0.019046\n0.019046\n256×256×1 -&gt; 1, f:1×1\n\n\n8\n8\n1\n1\n128\n0.021709\n0.020890\n128×128×8 -&gt; 1, f:1×1\n\n\n45\n1\n1\n1\n512\n0.022528\n0.020275\n512×512×1 -&gt; 1, f:1×1\n\n\n27\n3\n8\n1\n64\n0.026419\n0.014336\n64×64×3 -&gt; 8, f:1×1\n\n\n16\n3\n4\n1\n256\n0.031744\n0.033382\n256×256×3 -&gt; 4, f:1×1\n\n\n17\n1\n4\n5\n64\n0.035840\n0.022118\n64×64×1 -&gt; 4, f:5×5\n\n\n38\n1\n1\n1\n1024\n0.056525\n0.055706\n1024×1024×1 -&gt; 1, f:1×1\n\n\n40\n32\n1\n3\n128\n0.087450\n0.084378\n128×128×32 -&gt; 1, f:3×3\n\n\n4\n1\n8\n5\n256\n0.095232\n0.082739\n256×256×1 -&gt; 8, f:5×5\n\n\n37\n3\n8\n3\n256\n0.107520\n0.096256\n256×256×3 -&gt; 8, f:3×3\n\n\n36\n1\n8\n9\n128\n0.117555\n0.055910\n128×128×1 -&gt; 8, f:9×9\n\n\n5\n1\n4\n9\n256\n0.119194\n0.094003\n256×256×1 -&gt; 4, f:9×9\n\n\n43\n8\n4\n1\n512\n0.132710\n0.177357\n512×512×8 -&gt; 4, f:1×1\n\n\n19\n128\n1\n1\n256\n0.204186\n0.203981\n256×256×128 -&gt; 1, f:1×1\n\n\n39\n8\n8\n1\n512\n0.231834\n0.336896\n512×512×8 -&gt; 8, f:1×1\n\n\n13\n1\n8\n5\n512\n0.247194\n0.273203\n512×512×1 -&gt; 8, f:5×5\n\n\n24\n3\n8\n3\n512\n0.292659\n0.353075\n512×512×3 -&gt; 8, f:3×3\n\n\n10\n3\n8\n9\n64\n0.312934\n0.050995\n64×64×3 -&gt; 8, f:9×9\n\n\n0\n8\n4\n9\n64\n0.417997\n0.113254\n64×64×8 -&gt; 4, f:9×9\n\n\n32\n1\n512\n1\n128\n0.425779\n0.243507\n128×128×1 -&gt; 512, f:1×1\n\n\n31\n128\n4\n1\n256\n0.743834\n0.588595\n256×256×128 -&gt; 4, f:1×1\n\n\n26\n3\n512\n1\n64\n0.885965\n0.120422\n64×64×3 -&gt; 512, f:1×1\n\n\n18\n8\n4\n5\n512\n0.916275\n0.968294\n512×512×8 -&gt; 4, f:5×5\n\n\n1\n1\n512\n3\n128\n1.092198\n0.514048\n128×128×1 -&gt; 512, f:3×3\n\n\n46\n3\n32\n3\n512\n1.098752\n1.355366\n512×512×3 -&gt; 32, f:3×3\n\n\n9\n8\n4\n3\n1024\n1.419674\n2.212659\n1024×1024×8 -&gt; 4, f:3×3\n\n\n21\n1\n128\n1\n1024\n1.955635\n5.893126\n1024×1024×1 -&gt; 128, f:1×1\n\n\n3\n32\n4\n1\n1024\n2.050253\n2.409267\n1024×1024×32 -&gt; 4, f:1×1\n\n\n30\n512\n1\n3\n256\n2.841395\n2.728755\n256×256×512 -&gt; 1, f:3×3\n\n\n33\n8\n32\n9\n64\n3.557990\n0.306995\n64×64×8 -&gt; 32, f:9×9\n\n\n14\n8\n512\n1\n256\n4.713267\n4.175462\n256×256×8 -&gt; 512, f:1×1\n\n\n47\n32\n32\n5\n128\n5.372723\n1.687757\n128×128×32 -&gt; 32, f:5×5\n\n\n11\n128\n4\n5\n256\n5.690982\n3.754189\n256×256×128 -&gt; 4, f:5×5\n\n\n6\n512\n8\n1\n256\n6.060646\n4.183040\n256×256×512 -&gt; 8, f:1×1\n\n\n34\n3\n8\n9\n1024\n7.197081\n8.368333\n1024×1024×3 -&gt; 8, f:9×9\n\n\n25\n3\n32\n9\n512\n7.662797\n7.265075\n512×512×3 -&gt; 32, f:9×9\n\n\n12\n3\n32\n5\n1024\n10.742989\n14.039655\n1024×1024×3 -&gt; 32, f:5×5\n\n\n22\n512\n8\n3\n64\n11.946598\n1.192960\n64×64×512 -&gt; 8, f:3×3\n\n\n28\n1\n128\n5\n1024\n14.895719\n19.455181\n1024×1024×1 -&gt; 128, f:5×5\n\n\n23\n128\n4\n9\n256\n14.967603\n10.709811\n256×256×128 -&gt; 4, f:9×9\n\n\n35\n128\n8\n3\n512\n18.949939\n16.436429\n512×512×128 -&gt; 8, f:3×3\n\n\n7\n3\n512\n3\n512\n20.223590\n24.182989\n512×512×3 -&gt; 512, f:3×3\n\n\n20\n128\n32\n3\n256\n23.864934\n15.436800\n256×256×128 -&gt; 32, f:3×3\n\n\n44\n512\n4\n5\n256\n25.573376\n16.888422\n256×256×512 -&gt; 4, f:5×5\n\n\n48\n128\n8\n9\n256\n30.146976\n20.129997\n256×256×128 -&gt; 8, f:9×9\n\n\n15\n32\n8\n5\n1024\n35.380025\n33.746944\n1024×1024×32 -&gt; 8, f:5×5\n\n\n2\n32\n128\n9\n128\n59.110400\n19.480167\n128×128×32 -&gt; 128, f:9×9\n\n\n42\n128\n4\n5\n1024\n72.265121\n66.161868\n1024×1024×128 -&gt; 4, f:5×5\n\n\n29\n128\n512\n3\n64\n155.834366\n12.261376\n64×64×128 -&gt; 512, f:3×3\n\n\n41\n32\n512\n9\n64\n236.589465\n19.932570\n64×64×32 -&gt; 512, f:9×9",
    "crumbs": [
      "Day 10 - Improving Conv2d performance"
    ]
  },
  {
    "objectID": "day_06_matmul-tiled.html",
    "href": "day_06_matmul-tiled.html",
    "title": "Day 6 - Tiled matmul",
    "section": "",
    "text": "Let’start with a square matrix that is multiple of block width.\n\nTODO: Check what’s the performance penalty of the boundary check. It might be better to just force matrices to be multiple of block size with padding.\n\n\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file = \"kernels/matmul/matmul-tiled.cu\"\n\n\nkernels/matmul/matmul-tiled.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n// We will use square blocks to keep things sane.\n#define BLOCK_WIDTH 16\n\n__global__ void matmul_fp32_tiled(float *m1, float *m2, float *res, uint32_t out_shape_0,\n                                  uint32_t out_shape_1, uint32_t inner_dim, uint32_t) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    __shared__ float m1_tile[BLOCK_WIDTH][BLOCK_WIDTH];\n    __shared__ float m2_tile[BLOCK_WIDTH][BLOCK_WIDTH];\n\n    int m1_x = inner_dim;\n    int m2_x = out_shape_1;\n\n    // Assume the matrices are multiples my block size on both dims.\n\n    float R = 0;\n    for (int tile = 0; tile &lt; inner_dim / BLOCK_WIDTH; tile++) {\n        m1_tile[threadIdx.y][threadIdx.x] = m1[y * m1_x + tile * BLOCK_WIDTH + threadIdx.x];\n        m2_tile[threadIdx.y][threadIdx.x] = m2[(tile * BLOCK_WIDTH + threadIdx.y) * m2_x + x];\n\n        __syncthreads();\n\n        for (int i = 0; i &lt; BLOCK_WIDTH; i++) {\n            R += m1_tile[threadIdx.y][i] * m2_tile[i][threadIdx.x];\n        }\n\n        __syncthreads();\n    }\n\n    res[y * out_shape_1 + x] = R;\n}\n\n\nfrom lovely_numpy import Lo\n\n\nm1 = np.random.randn(1024, 1024).astype(np.float32)\nm2 = np.random.randn(1024, 1024).astype(np.float32)\n\nnp_res = np.matmul(m1, m2)\nLo(np_res)\n\narray[1024, 1024] f32 n=1048576 (4Mb) x∈[-146.704, 153.927] μ=-0.014 σ=32.009\n\n\n\nBLOCK_SIZE = 16 # 16x16\n\nassert(len(m1.shape) == 2)\nassert(len(m2.shape) == 2)\nassert(m1.shape == m2.shape) # Make them equal for now\n\nout_shape = (m1.shape[0], m2.shape[1])\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(cu_file).read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    matmul_tiled = mod.get_function(\"matmul_fp32_tiled\")\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res = np.empty(out_shape, dtype=np.float32)\n\n    gpu_res = cuda.mem_alloc_like(res)\n\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n\n    block_size = (BLOCK_SIZE, BLOCK_SIZE, 1)\n    grid_size = (\n        ((out_shape[1] + BLOCK_SIZE - 1) // BLOCK_SIZE),\n        ((out_shape[0] + BLOCK_SIZE - 1) // BLOCK_SIZE),\n        1\n    )\n\n\n    print(f\"Matrix 1 shape: {m1.shape}\")\n    print(f\"Matrix 2 shape: {m2.shape}\")\n    print(f\"Result shape: {out_shape}\")\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n    ctx.synchronize()\n\n    matmul_tiled(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[1]), np.uint32(out_shape[0]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n\n    ctx.synchronize()\n\n    cuda.memcpy_dtoh(res, gpu_res)\n    ctx.synchronize()\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nLo(res)\n\nMatrix 1 shape: (1024, 1024)\nMatrix 2 shape: (1024, 1024)\nResult shape: (1024, 1024)\nGrid size: (64, 64, 1)\nBlock size: (16, 16, 1)\nTotal threads: 1048576\n\n\narray[1024, 1024] f32 n=1048576 (4Mb) x∈[-146.704, 153.927] μ=-0.014 σ=32.009\n\n\n\nfloat(np.isclose(res, np_res).mean())\n\n0.9787321090698242\n\n\n\n\nNumerical stability\nWe have the same numerical error situation as with naive matmul, let’s compare with the non-tiled result - it should match exactly.\n\nBLOCK_SIZE = 16 # 16x16\n\nassert(len(m1.shape) == 2)\nassert(len(m2.shape) == 2)\nassert(m1.shape == m2.shape) # Make them equal for now\n\nout_shape = (m1.shape[0], m2.shape[1])\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(\"kernels/matmul/matmul.cu\").read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    matmul_naive = mod.get_function(\"matmul_f32\")\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res_naive = np.empty(out_shape, dtype=np.float32)\n\n    gpu_res_naive = cuda.mem_alloc_like(res)\n\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n\n    block_size = (BLOCK_SIZE, BLOCK_SIZE, 1)\n    grid_size = (\n        ((out_shape[1] + BLOCK_SIZE - 1) // BLOCK_SIZE),\n        ((out_shape[0] + BLOCK_SIZE - 1) // BLOCK_SIZE),\n        1\n    )\n\n\n    print(f\"Matrix 1 shape: {m1.shape}\")\n    print(f\"Matrix 2 shape: {m2.shape}\")\n    print(f\"Result shape: {out_shape}\")\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n    ctx.synchronize()\n\n    matmul_naive(gpu_m1, gpu_m2, gpu_res_naive, np.uint32(out_shape[1]), np.uint32(out_shape[0]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n\n    ctx.synchronize()\n\n    cuda.memcpy_dtoh(res_naive, gpu_res_naive)\n    ctx.synchronize()\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nLo(res_naive)\n\nMatrix 1 shape: (1024, 1024)\nMatrix 2 shape: (1024, 1024)\nResult shape: (1024, 1024)\nGrid size: (64, 64, 1)\nBlock size: (16, 16, 1)\nTotal threads: 1048576\n\n\narray[1024, 1024] f32 n=1048576 (4Mb) x∈[-146.704, 153.927] μ=-0.014 σ=32.009\n\n\n\nnp.isclose(res, res_naive).all()\n\nnp.True_\n\n\nYaaay, they match. This was the first attempt based on memory/understading of what I read in chapter 4, and it worked on the first try 😎",
    "crumbs": [
      "Day 6 - Tiled matmul"
    ]
  },
  {
    "objectID": "day_09_conv2d.html",
    "href": "day_09_conv2d.html",
    "title": "Day 9 - Conv 2D",
    "section": "",
    "text": "Unlike the book, I’m going to implement convolution with arbitrary number of input and output channels\n\n\n\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\n\n\nfrom lovely_numpy import Lo\nfrom lovely_tensors import monkey_patch; monkey_patch()\nfrom torch import Tensor\nfrom torch.nn.functional import conv2d\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file=\"kernels/conv2d/conv2d_naive.cu\"\n\n\nkernels/conv2d/conv2d_naive.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n#include \"conv2d-helpers.h\"\n\n/* 2D convolution, with padding to valid shape. Channel-first */\n__global__ void conv2d_pad(float *in,\n                           float *out,\n                           float *filter,\n                           int h,\n                           int w,\n                           int in_channels,\n                           int out_channels,\n                           int filter_size /* Must be an odd number */,\n                           float pad) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int filter_r = (filter_size - 1) / 2;\n\n\n    // In and Out data dimensions:\n    // 0 - channel\n    // 1 - height\n    // 2 - width\n\n    // Filter dimensions:\n    // 0 - out channels\n    // 1 - in channels\n    // 2 - height\n    // 3 - width\n\n    if (x &gt;= w || y &gt;= h) return;\n\n#ifdef DEBUG\n    if (x == 0 && y == 0) {\n        PRINT_INPUTS();\n    }\n#endif\n\n\n    // Loop over the output channels\n    for (int out_c = 0; out_c &lt; out_channels; out_c++) {\n        ACCUM_DTYPE R = 0;\n\n        // Pointer to the 2d slice of the output\n        float *sub_output = out + out_c * w * h;\n\n        // Loop over the input channels\n        for (int in_c = 0; in_c &lt; in_channels; in_c++) {\n            // Pointer to the 2d slice of the filter that corresponds to the active input and output\n            // channels\n            float *sub_filter = filter + (filter_size * filter_size * in_channels * out_c) +\n                                (filter_size * filter_size * in_c);\n            // Pinter to the current channel in the input\n            float *sub_input = in + (w * h * in_c);\n\n            // Apply the filter to the input or the pad value for outside indices.\n            for (int filter_y = 0; filter_y &lt; filter_size; filter_y++) {\n                for (int filter_x = 0; filter_x &lt; filter_size; filter_x++) {\n                    float v = pad;\n                    int input_x = x - filter_r + filter_x;\n                    int input_y = y - filter_r + filter_y;\n\n                    if (input_x &gt;= 0 && input_x &lt; w && input_y &gt;= 0 && input_y &lt; h) {\n                        v = sub_input[input_y * w + input_x];\n                    }\n                    R += v * sub_filter[filter_y * filter_size + filter_x];\n                }\n            }\n        }\n        sub_output[y * w + x] = R;\n    }\n}\n\n\ndef benchmark_conv2d_pad(ctx, kernel, input, filter, pad, block_size, grid_size, repeat=10, warmup=True):\n    # input, channel-first\n    # - Channel\n    # - Height\n    # - Width\n    assert len(input.shape) == 3\n\n    # Filter shape should be\n    # - Out channels\n    # - In  channels\n    # - Height\n    # - Width\n    assert len(filter.shape) == 4\n\n    in_ch, h, w = input.shape\n    out_ch, in_ch2, fh, fw = filter.shape\n\n    assert fh == fw, f\"Only square filters supported, got shape={filter.shape}\"\n\n    assert in_ch == in_ch2\n\n    out_shape = (out_ch, h, w)\n\n    gpu_input = cuda.mem_alloc_like(input)\n    gpu_filter = cuda.mem_alloc_like(filter)\n\n    out = np.empty(out_shape, dtype=np.float32)\n\n    cuda.memcpy_htod(gpu_input, input)\n    cuda.memcpy_htod(gpu_filter, filter)\n    ctx.synchronize()\n\n    timing=0\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n        gpu_out = cuda.mem_alloc_like(out)\n\n        if warmup:\n            kernel(gpu_input, gpu_out, gpu_filter,\n                   np.int32(h),\n                   np.int32(w),\n                   np.int32(in_ch),\n                   np.int32(out_ch),\n                   np.int32(fh),\n                   np.float32(pad),\n                   grid=grid_size,\n                   block=block_size)\n            ctx.synchronize()\n\n        start.record()\n        kernel(gpu_input, gpu_out, gpu_filter,\n               np.int32(h),\n               np.int32(w),\n               np.int32(in_ch),\n               np.int32(out_ch),\n               np.int32(fh),\n               np.float32(pad),\n               grid=grid_size,\n               block=block_size)\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n\n    cuda.memcpy_dtoh(out, gpu_out)\n    return out, timing;\n\n\ninput = Image.open(\"../cat-1.jpg\")\ninput_array = np.ascontiguousarray(np.array(input).transpose(2, 0, 1)).astype(np.float32) / 256\n\n# input_array = np.linspace(0, 0.5, 3*32*32).reshape(3, 32, 32).astype(np.float32) + 0.5\n\n# Convert from HWC to CHW format\n# input_array = np.ascontiguousarray(input_array.transpose(2, 0, 1))[:1,:,:]\nprint(Lo(input_array))\nLo(input_array).chans(cl=False)\n\narray[3, 600, 451] f32 n=811800 (3.1Mb) x∈[0., 0.996] μ=0.592 σ=0.147\n\n\n\n\n\n\n\n\n\n\nout_channels = 4\nfilter_size = 3\n\nfilter = np.random.randn(out_channels, input_array.shape[0], filter_size, filter_size).astype(np.float32) / 5\n\n# This filter does nothing to the input image.\n# filter = np.array([\n#     [[[0, 0, 0],\n#       [0, 1, 0],\n#       [0, 0 ,0]]]\n#     ]).astype(np.float32)\n\n\nLo(filter)\n\narray[4, 3, 3, 3] f32 n=108 x∈[-0.489, 0.506] μ=-0.017 σ=0.190\n\n\n\n# input_array = np.random.randn(3, 64,64).astype(np.float32)\n\ntorch_res = conv2d(Tensor(input_array), Tensor(filter), padding=\"same\")\nprint(torch_res)\ntorch_res.chans(scale=1)\n\ntensor[4, 600, 451] n=1082400 (4.1Mb) x∈[-1.707, 0.952] μ=-0.247 σ=0.531\n\n\n\n\n\n\n\n\n\n\nimport warn_options\n\n\ntile_width = 32\nch, h, w = input_array.shape\n\nctx = device.make_context()\ntry:\n    mod = SourceModule(\n        Path(cu_file).read_text(),\n        options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\"], include_dirs=[str(Path(cu_file).parent.absolute())])\n\n    kernel = mod.get_function(\"conv2d_pad\")\n\n\n    block_size = (tile_width,tile_width,1)\n    grid_size = (\n        ((w + tile_width - 1) // tile_width),\n        ((h + tile_width - 1) // tile_width),\n        1\n    )\n\n\n    print(f\"Input shape: {input_array.shape}\")\n    print(f\"Filter shape: {filter.shape}\")\n    print(f\"Result shape: {(filter.shape[0], input_array.shape[1], input_array.shape[2])}\")\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n\n    res, timing = benchmark_conv2d_pad(ctx, kernel, input_array, filter, 0, block_size, grid_size, repeat=1, warmup=False)\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nprint(Lo(res))\nprint(f\"Took {timing:.3f}ms\")\n\nInput shape: (3, 600, 451)\nFilter shape: (4, 3, 3, 3)\nResult shape: (4, 600, 451)\nGrid size: (15, 19, 1)\nBlock size: (32, 32, 1)\nTotal threads: 291840\narray[4, 600, 451] f32 n=1082400 (4.1Mb) x∈[-1.707, 0.952] μ=-0.247 σ=0.531\nTook 0.210ms\n\n\n\nfloat(np.isclose(res, torch_res).mean())\n\n0.9978085735402809\n\n\nLooks good!\nI’ll leave benchmarks and performance improvements for tomorrow.",
    "crumbs": [
      "Day 9 - Conv 2D"
    ]
  },
  {
    "objectID": "day_01_nvcc.html",
    "href": "day_01_nvcc.html",
    "title": "Day 1 - playing with nvcc",
    "section": "",
    "text": "from pathlib import Path\n\n\ncu_file = \"day_01_nvcc/src/hello.cu\"\n\n\nday_01_nvcc/src/hello.cu\n\n#include &lt;stdio.h&gt;\n#include &lt;cuda_runtime.h&gt;\n\n\n#ifndef N_THREADS\n    #define N_THREADS 512\n#endif\n\n\n__global__ void testKernel(float *a, float *b, float *c, uint n)\n{\n    int i = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (i &lt; n) {\n        c[i] = a[i]+ b[i];\n    }\n\n}\n\n\nvoid vecAdd_f32(float *A, float *B, float *C, uint n) {\n    float *A_d, *B_d, *C_d;\n    int size = n * sizeof(float);\n\n    cudaMalloc((void **) &A_d, size);\n    cudaMalloc((void **) &B_d, size);\n    cudaMalloc((void **) &C_d, size);\n\n\n    cudaMemcpy(A_d, A, size, cudaMemcpyHostToDevice);\n    cudaMemcpy(B_d, B, size, cudaMemcpyHostToDevice);\n\n    testKernel &lt;&lt;&lt;(n + N_THREADS - 1) / N_THREADS, N_THREADS&gt;&gt;&gt;(A_d, B_d, C_d, n);\n\n    cudaMemcpy(C, C_d, size, cudaMemcpyDeviceToHost);\n\n    cudaFree(A_d);\n    cudaFree(B_d);\n    cudaFree(C_d);\n}\n\n\n\nvoid add_vectors_cpu(float *a, float *b, float *c, uint n) {\n    for (uint i = 0; i &lt; n; i++) {\n        c[i] = a[i] + b[i];\n    }\n}\n\nint verify_equal(float *a, float *b, uint n)\n{\n    for (uint i = 0; i &lt; n; i++) {\n        if (a[i] != b[i]) return 0;\n    }\n    return 1;\n\n}\n\n\nint main() {\n    uint n = 1024*1024;\n\n    float *A = (float*)malloc(n * sizeof(float));\n    float *B = (float*)malloc(n * sizeof(float));\n    float *C = (float*)malloc(n * sizeof(float));\n\n\n    for(uint i = 0; i &lt; n; i++) {\n        A[i] = (float)rand() / RAND_MAX;\n        B[i] = (float)rand() / RAND_MAX;\n    }\n\n    vecAdd_f32(A, B, C, n);\n\n    float *C_cpu = (float *)malloc(n * sizeof(float));\n\n    add_vectors_cpu(A, B, C_cpu, n);\n\n    printf(\"Do they match? %s!\\n\", verify_equal(C, C_cpu, n) ? \"Yes\" : \"No\" );\n\n    return 0;\n}\n\n\nmake_file = \"day_01_nvcc/Makefile\"\n\n\n\nday_01_nvcc/Makefile\n\n# Compiler and flags\nNVCC        := nvcc\nCUDA_ARCH   := -arch=sm_60 -gencode=arch=compute_60,code=sm_60 \\\n               -gencode=arch=compute_70,code=sm_70 \\\n               -gencode=arch=compute_75,code=sm_75\n\n# Build flags\nNVCC_FLAGS  := -std=c++14 -O3 $(CUDA_ARCH)\nWARN_FLAGS  := -Xcompiler -Wall,-Wextra\nDEBUG_FLAGS := -g -G -lineinfo\n\n# Build directories\nBUILD_DIR   := build\nSRC_DIR     := src\n\n# Default target name\nTARGET      := hello\n\n# Source files\nSRCS        := $(wildcard $(SRC_DIR)/*.cu)\nOBJS        := $(SRCS:$(SRC_DIR)/%.cu=$(BUILD_DIR)/%.o)\n\n# Build targets\nall: release\n\ndebug: NVCC_FLAGS += $(DEBUG_FLAGS)\ndebug: $(BUILD_DIR)/$(TARGET)\n\nrelease: $(BUILD_DIR)/$(TARGET)\n\n$(BUILD_DIR)/$(TARGET): $(OBJS)\n    mkdir -p $(@D)\n    $(NVCC) $(NVCC_FLAGS) $(WARN_FLAGS) $^ -o $@\n\n$(BUILD_DIR)/%.o: $(SRC_DIR)/%.cu\n    mkdir -p $(@D)\n    $(NVCC) $(NVCC_FLAGS) $(WARN_FLAGS) -c $&lt; -o $@\n\nclean:\n    rm -rf $(BUILD_DIR)\n\n.PHONY: all debug release clean",
    "crumbs": [
      "Day 1 - playing with nvcc"
    ]
  },
  {
    "objectID": "day_05_matrix-vector.html",
    "href": "day_05_matrix-vector.html",
    "title": "Day 5 - Matrix-vector multiplication",
    "section": "",
    "text": "Chapter 3 exercise 2.\nA matrix-vector multiplication takes an input matrix B and a vector C\nand produces one output vector A. Each element of the output vector A\nis the dot  product of one row of the input matrix B and C, that is,\nA[i] = sum{j} (B[i][j] * C[j]). For simplicity we will handle only square\nmatrices whose elements are singleprecision floating-point numbers. Write\na matrix-vector multiplication kernel and the host stub function that can\nbe called with four parameters: pointer to the output matrix, pointer to\nthe input matrix, pointer to the input vector, and the number of elements\nin each dimension. Use one thread to calculate an output vector element.\n\nI will actually implement it for any shape matrices.\n\n\n\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file = \"kernels/misc/matrix-vector-mul.cu\"\n\n\nkernels/misc/matrix-vector-mul.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n__global__ void mat_vec_mul(float* m, float* v, float* res,\n                            uint32_t m_height,\n                            uint32_t m_width) {\n\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    float out;\n    if (y &lt; m_height) {\n        out = 0;\n        for (int i = 0; i &lt; m_width; i++) {\n            out += m[y * m_width + i] * v[i];\n        }\n        res[y] = out;\n    }\n}\n\n\nfrom lovely_numpy import Lo\n\n\nm = np.random.randn(2000, 1000).astype(np.float32)\nv = np.random.randn(1000).astype(np.float32)\n\nnp_res = m @ v\nLo(np_res)\n\narray[2000] f32 7.8Kb x∈[-101.809, 89.337] μ=-0.495 σ=31.320\n\n\n\n\nTesting the kernel\n\nBLOCK_SIZE_X = 1\nBLOCK_SIZE_Y = 128\n\nassert(len(m.shape) == 2)\nassert(len(v.shape) == 1)\nassert(m.shape[1] == v.shape[0])\n\nout_dim = m.shape[0]\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(cu_file).read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    mat_vec_mul = mod.get_function(\"mat_vec_mul\")\n\n    gpu_m = cuda.mem_alloc_like(m)\n    gpu_v = cuda.mem_alloc_like(v)\n\n    res = np.empty((out_dim, ), dtype=np.float32)\n\n    gpu_res = cuda.mem_alloc_like(res)\n\n\n    cuda.memcpy_htod(gpu_m, m)\n    cuda.memcpy_htod(gpu_v, v)\n\n    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n    grid_size = (\n        1,\n        ((out_dim + BLOCK_SIZE_Y - 1) // BLOCK_SIZE_Y),\n        1\n    )\n\n\n    print(f\"Matrix shape: {m.shape}\")\n    print(f\"Vector shape: {v.shape}\")\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Result dimension: {out_dim}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n    ctx.synchronize()\n\n    mat_vec_mul(gpu_m, gpu_v, gpu_res, np.uint32(m.shape[0]), np.uint32(m.shape[1]), grid=grid_size, block=block_size)\n\n    ctx.synchronize()\n\n    cuda.memcpy_dtoh(res, gpu_res)\n    ctx.synchronize()\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nLo(res)\n\nMatrix shape: (2000, 1000)\nVector shape: (1000,)\nGrid size: (1, 16, 1)\nBlock size: (1, 128, 1)\nResult dimension: 2000\nTotal threads: 2048\n\n\narray[2000] f32 7.8Kb x∈[-101.809, 89.337] μ=-0.495 σ=31.320\n\n\n\nnp.isclose(res, np_res)\n\narray([ True,  True,  True, ...,  True,  True,  True], shape=(2000,))\n\n\n\nnp.isclose(res, np_res).mean()\n\nnp.float64(0.9825)\n\n\n\n\nNumerical stability\nWe have the same numerical error situation as with matmul, but seems to work fine otherwise.",
    "crumbs": [
      "Day 5 - Matrix-vector multiplication"
    ]
  },
  {
    "objectID": "day_03_blurry.html",
    "href": "day_03_blurry.html",
    "title": "Day 3 - RGB blur",
    "section": "",
    "text": "import numpy as np\nfrom PIL import Image\n\n\nimage = Image.open(\"../cat-1.jpg\")\nimage\n\n\n\n\n\n\n\n\n\n# Convert PIL Image to numpy array\nimg_array = np.array(image)\nprint(f\"Image shape: {img_array.shape}\")\n\nheight = img_array.shape[0]\nwidth = img_array.shape[1]\n\nImage shape: (600, 451, 3)\n\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\nfrom pathlib import Path\n\n\ncu_file = \"kernels/misc/rgb_blur.cu\"\n\n\nkernels/misc/rgb_blur.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n__global__ void rgb_blur(uint8_t *in, uint8_t *out, uint32_t w, uint32_t h, uint32_t blur) {\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x &lt; w && y &lt; h) {\n        int idx = (y * w + x);\n\n        for (int ch = 0; ch &lt; 3; ch++) {\n            uint32_t v = 0;\n            for (int j = -blur; j &lt;= (int)blur; j++) {\n                for (int i = -blur; i &lt;= (int)blur; i++) {\n                    if (y + j &gt;= 0   &&\n                        y + j &lt; h    &&\n                        x + i &gt;= 0   &&\n                        x + i &lt; w) {\n                            v += in[ ((y + j) * w + x + i)*3 + ch];\n                        }\n                }\n            }\n\n            out[idx*3+ch] = (uint8_t)(v / ((2*blur + 1) * (2*blur + 1)));\n        }\n    }\n}\n\n\n\n\nTesting the kernel\n\nBLOCK_SIZE_X = 16\nBLOCK_SIZE_Y = 16\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(cu_file).read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    rgb_blur = mod.get_function(\"rgb_blur\")\n\n    gpu_in = cuda.mem_alloc_like(img_array)\n    gpu_out = cuda.mem_alloc_like(img_array)\n\n\n    cuda.memcpy_htod(gpu_in, img_array)\n\n    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n    grid_size = (\n        ((width + BLOCK_SIZE_X - 1) // BLOCK_SIZE_X),\n        ((height + BLOCK_SIZE_Y - 1) // BLOCK_SIZE_Y),\n        1\n    )\n\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Image dimensions: {width}x{height}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n\n    rgb_blur(gpu_in, gpu_out, np.uint32(width), np.uint32(height), np.int32(3), block=block_size, grid=grid_size)\n\n    cpu_out = np.empty_like(img_array)\n    cuda.memcpy_dtoh(cpu_out, gpu_out)\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nGrid size: (29, 38, 1)\nBlock size: (16, 16, 1)\nImage dimensions: 451x600\nTotal threads: 282112\n\n\n\nImage.fromarray(cpu_out)",
    "crumbs": [
      "Day 3 - RGB blur"
    ]
  },
  {
    "objectID": "day_08_thread-coarsening.html",
    "href": "day_08_thread-coarsening.html",
    "title": "Day 8 - Thread coarsening",
    "section": "",
    "text": "import numpy as np\nfrom PIL import Image\nfrom pathlib import Path\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file=\"kernels/matmul/matmul-thread-coarsening.cu\"\n\n\nkernels/matmul/matmul-thread-coarsening.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n#ifndef TILE_WIDTH\n#ifdef __INTELLISENSE__\n#define TILE_WIDTH 16\n#else\n#error \"TILE_WIDTH must be defined\"\n#endif\n#endif\n\n#ifndef THREAD_COARSENING\n#ifdef __INTELLISENSE__\n#define THREAD_COARSENING 2\n#else\n#error \"THREAD_COARSENING must be defined\"\n#endif\n#endif\n\n__global__ void matmul_fp32_tiled_coarse(float *m1, float *m2, float *res, uint32_t out_shape_0,\n                                         uint32_t out_shape_1, uint32_t inner_dim, uint32_t) {\n    int x = blockIdx.x * blockDim.x * THREAD_COARSENING + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // if (threadIdx.x == 0 && threadIdx.y == 0) {\n    //     printf(\"blockIdx = (%d, %d), mx = %d, y = %d\\n\", blockIdx.x, blockIdx.y, x, y);\n    // }\n\n    __shared__ float m1_tile[TILE_WIDTH][TILE_WIDTH];\n    __shared__ float m2_tile[TILE_WIDTH][TILE_WIDTH];\n\n    float R[THREAD_COARSENING];\n    for (int i = 0; i &lt; THREAD_COARSENING; i++) {\n        R[i] = 0;\n    }\n\n    int m1_x = inner_dim;\n    int m2_x = out_shape_1;\n\n    // We are going to coarse the thread over x, so let's load the tile from the\n    // second matrix.\n\n    for (int tile = 0; tile &lt; inner_dim / TILE_WIDTH; tile++) {\n        m1_tile[threadIdx.y][threadIdx.x] = m1[y * m1_x + tile * TILE_WIDTH + threadIdx.x];\n\n        // Now, we are going to calculate a bunch consecutive tiles one by one,\n        // so we need to load the\n        for (int c = 0; c &lt; THREAD_COARSENING; c++) {\n            m2_tile[threadIdx.y][threadIdx.x] =\n                m2[(tile * TILE_WIDTH + threadIdx.y) * m2_x + c * TILE_WIDTH + x];\n\n            __syncthreads();\n\n            for (int i = 0; i &lt; TILE_WIDTH; i++) {\n                R[c] += m1_tile[threadIdx.y][i] * m2_tile[i][threadIdx.x];\n            }\n\n            __syncthreads();\n        }\n    }\n\n    for (int c = 0; c &lt; THREAD_COARSENING; c++) {\n        res[y * out_shape_1 + c * TILE_WIDTH + x] = R[c];\n    }\n}\n\n\nfrom lovely_numpy import Lo\n\n\n## Compiler options for more compile-time warnings.\nwarn_options=[\n    '-Xcompiler', '-Wall',\n    '-Xcompiler', '-Wextra',\n    '-Xcompiler', '-Wsign-conversion',\n    '-Xcompiler', '-Wcast-qual',\n    '-Xcompiler', '-Wunused-parameter',\n    '-Xcompiler', '-Wdouble-promotion',\n    '-Xcompiler', '-Wformat=2',\n    '-Xcompiler', '-Wfloat-equal',\n    '-Xcompiler', '-Wshadow'\n]\n\n\ndef benchmark_matmul(ctx, kernel, m1, m2, block_size, grid_size, repeat=10, warmup=True):\n    assert len(m1.shape) == 2\n    assert len(m2.shape) == 2\n    assert m1.shape[1] == m2.shape[0]\n\n    out_shape = (m1.shape[0], m2.shape[1])\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res = np.empty(out_shape, dtype=np.float32)\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n    ctx.synchronize()\n\n    timing=0\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n        gpu_res = cuda.mem_alloc_like(res)\n\n        if warmup:\n            kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n            ctx.synchronize()\n\n        start.record()\n        kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n\n    cuda.memcpy_dtoh(res, gpu_res)\n    return res, timing\n\n\nm1 = np.random.randn(8192, 8192).astype(np.float32)\nm2 = np.random.randn(8192, 8192).astype(np.float32)\n\nnp_res = np.matmul(m1, m2)\n\ntile_width = 32\ncoarsening = 4\n\nctx = device.make_context()\ntry:\n    mod = SourceModule(\n        Path(cu_file).read_text(),\n        options=warn_options + [\n            f\"-D TILE_WIDTH={tile_width}\",\n            f\"-D THREAD_COARSENING={coarsening}\"\n            ])\n\n    kernel = mod.get_function(\"matmul_fp32_tiled_coarse\")\n\n    out_shape = (m1.shape[0], m2.shape[1])\n\n    block_size = (tile_width, tile_width, 1)\n    grid_size = (\n        ((out_shape[1] + tile_width * coarsening - 1) // (tile_width * coarsening)),\n        ((out_shape[0] + tile_width - 1) // tile_width),\n        1\n    )\n\n\n    print(f\"Matrix 1 shape: {m1.shape}\")\n    print(f\"Matrix 2 shape: {m2.shape}\")\n    print(f\"Result shape: {out_shape}\")\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n\n    res, timing = benchmark_matmul(ctx, kernel, m1, m2, block_size, grid_size, repeat=2, warmup=True)\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nprint(Lo(res))\nprint(f\"Took {timing:.3f}ms\")\n\nMatrix 1 shape: (8192, 8192)\nMatrix 2 shape: (8192, 8192)\nResult shape: (8192, 8192)\nGrid size: (64, 256, 1)\nBlock size: (32, 32, 1)\nTotal threads: 16777216\narray[8192, 8192] f32 n=67108864 (0.2Gb) x∈[-517.091, 500.085] μ=0.005 σ=90.506\nTook 1331.796ms\n\n\n\nnp.isclose(res, np_res).mean()\n\nnp.float64(0.9412752240896225)\n\n\n\n\nRun the test\n\ndef benchmark(dim, tile_width, coarsening):\n    m1 = np.random.randn(dim, dim).astype(np.float32)\n    m2 = np.random.randn(dim, dim).astype(np.float32)\n\n    ctx = device.make_context()\n    try:\n        mod = SourceModule(\n            Path(cu_file).read_text(),\n            options=warn_options + [\n                f\"-D TILE_WIDTH={tile_width}\",\n                f\"-D THREAD_COARSENING={coarsening}\"\n                ])\n\n        kernel = mod.get_function(\"matmul_fp32_tiled_coarse\")\n\n        out_shape = (m1.shape[0], m2.shape[1])\n\n        block_size = (tile_width, tile_width, 1)\n        grid_size = (\n            ((out_shape[1] + tile_width * coarsening - 1) // (tile_width * coarsening)),\n            ((out_shape[0] + tile_width - 1) // tile_width),\n            1\n        )\n\n        # print(f\"Matrix 1 shape: {m1.shape}\")\n        # print(f\"Matrix 2 shape: {m2.shape}\")\n        # print(f\"Result shape: {out_shape}\")\n        # print(f\"Grid size: {grid_size}\")\n        # print(f\"Block size: {block_size}\")\n        # print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n\n        res, timing = benchmark_matmul(ctx, kernel, m1, m2, block_size, grid_size, repeat=2, warmup=True)\n    finally:\n        ctx.pop()\n        ctx.detach()\n\n    return res, timing\n\n\n\nprint(\"Matmul 8192x8192 with tile size 32x32 and thread coarsening along x:\")\nfor c in [1, 2, 4, 8]:\n    res, timing = benchmark(8192, 32, c)\n    print(f\"coarsening = {c}: {timing:.2f}ms\")\n\nMatmul 8192x8192 with tile size 32x32 and thread coarsening along x:\ncoarsening = 1: 1357.31ms\ncoarsening = 2: 1323.33ms\ncoarsening = 4: 1300.67ms\ncoarsening = 8: 1300.94ms\n\n\nCoarsening helps, but only a small bit.",
    "crumbs": [
      "Day 8 - Thread coarsening"
    ]
  },
  {
    "objectID": "day_02_grayscale.html",
    "href": "day_02_grayscale.html",
    "title": "Day 2 - RGB to grayscale",
    "section": "",
    "text": "import numpy as np\nfrom PIL import Image\n\n\nimage = Image.open(\"../cat-1.jpg\")\nimage\n\n\n\n\n\n\n\n\n\n# Convert PIL Image to numpy array\nimg_array = np.array(image)\nprint(f\"Image shape: {img_array.shape}\")\n\nheight = img_array.shape[0]\nwidth = img_array.shape[1]\n\nImage shape: (600, 451, 3)\n\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\nBLOCK_SIZE_X = 32\nBLOCK_SIZE_Y = 32\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(\n        \"\"\"\n            #include &lt;stdint.h&gt;\n\n            __global__ void rgb2gray(uint8_t *in, uint8_t *out, uint32_t w, uint32_t h)\n            {\n\n                int x = blockIdx.x * blockDim.x + threadIdx.x;\n                int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n                if (x &lt; w && y &lt; h) {\n                    int idx = (y * w + x);\n\n                    uint8_t r = in[idx * 3    ];\n                    uint8_t g = in[idx * 3 + 1];\n                    uint8_t b = in[idx * 3 + 2];\n\n                    out[idx] = 0.21 * r + 0.72*g + 0.07*b;\n                }\n            }\n        \"\"\")\n\n    rgb2gray = mod.get_function(\"rgb2gray\")\n\n    gpu_array = cuda.mem_alloc_like(img_array)\n    gpu_gray_array = cuda.mem_alloc(width * height)\n\n    cuda.memcpy_htod(gpu_array, img_array)\n\n    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n    grid_size = (\n        ((width + BLOCK_SIZE_X - 1) // BLOCK_SIZE_X),\n        ((height + BLOCK_SIZE_Y - 1) // BLOCK_SIZE_Y),\n        1\n    )\n\n    rgb2gray(gpu_array, gpu_gray_array, np.uint32(width), np.uint32(height), block=block_size, grid=grid_size)\n\n    cpu_gray_array = np.empty(shape=(height, width), dtype=np.uint8)\n    cuda.memcpy_dtoh(cpu_gray_array, gpu_gray_array)\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\n\nImage.fromarray(cpu_gray_array, mode='L')\n\n\n\n\n\n\n\n\n\nLooks good to me",
    "crumbs": [
      "Day 2 - RGB to grayscale"
    ]
  },
  {
    "objectID": "day_00_pycuda.html",
    "href": "day_00_pycuda.html",
    "title": "Day 0 - playing with PyCUDA",
    "section": "",
    "text": "import pycuda.driver as cuda\ncuda.init()\n\n\nLet’s see what kind of GPUs we got\n\nMiB = 1024*1024\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\n\nfor i in range(cuda.Device.count()):\n    device = cuda.Device(i)\n\n    attrs = device.get_attributes()\n    context = device.make_context()\n\n    free_bytes, total_bytes = cuda.mem_get_info()\n    used_bytes = total_bytes - free_bytes\n\n    context.pop()\n    context.detach()\n\n    print(\n        f\"Device {i}:\\t{device.name()}\\n\"\n        f\"\\t\\tCompute capability: {\".\".join([str(i) for i in device.compute_capability()])}\\n\"\n        f\"\\t\\tVRAM used: {used_bytes // MiB}MiB / {total_bytes // MiB}MiB\\n\"\n\n    )\n\nCuda version: 12.8.0\nDevice 0:   NVIDIA GeForce RTX 3080 Laptop GPU\n        Compute capability: 8.6\n        VRAM used: 2129MiB / 15983MiB\n\n\n\n\n\n\n\n!nvidia-smi | head -n 12\n\nTue Mar 25 19:29:27 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce RTX 3080 ...    Off |   00000000:01:00.0  On |                  N/A |\n| N/A   57C    P0             30W /  115W |    1966MiB /  16384MiB |      7%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n\n\nFor some reason we get slightly less VRAM that’s shown by nvidia-smi. I guess it’s the memory reserved for CUDA stuff.\n\n\nLet’s move some data in and out of the GPU.\n\nimport numpy as np\n\ndevice = cuda.Device(0)\n\ntry:\n    ctx = device.make_context()\n\n    cpu_array = np.random.randn(1024,1024).astype(np.float32)\n    gpu_array = cuda.mem_alloc_like(cpu_array)\n\n    cuda.memcpy_htod(gpu_array, cpu_array)\n\n    cpu_array_2 = np.empty_like(cpu_array, dtype=np.float32)\n\n    cuda.memcpy_dtoh(cpu_array_2, gpu_array)\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\n\n(cpu_array == cpu_array_2).all()\n\nnp.True_\n\n\n\n\nLooks ok. Let’s try doing something with the data on the GPU.\n\nfrom pycuda.compiler import SourceModule\n\nctx = device.make_context()\n\ntry:\n  # Slightly expanded code from their tutorial.\n  mod = SourceModule(\"\"\"\n      __global__ void doublify(float *a)\n      {\n\n        int x = blockIdx.x * blockDim.x + threadIdx.x;\n        int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n        int idx = y * blockDim.x * gridDim.x + x;\n\n        a[idx] *= 2;\n      }\n      \"\"\")\n\n  doublify = mod.get_function(\"doublify\")\n\n  # For a 1024x1024 array, we use a 32x32 grid of 32x32 blocks.\n  block_size = (32,32,1)\n  grid_size = (32,32,1)\n\n  cpu_array = np.random.randn(1024, 1024).astype(np.float32)\n  gpu_array = cuda.mem_alloc_like(cpu_array)\n  cpu_array_2 = np.empty_like(cpu_array, dtype=np.float32)\n\n  cuda.memcpy_htod(gpu_array, cpu_array)\n\n  doublify(gpu_array, block=block_size, grid=grid_size)\n\n  cuda.memcpy_dtoh(cpu_array_2, gpu_array)\n\n\nfinally:\n  ctx.pop()\n  ctx.detach()\n\n\n(cpu_array_2 == (cpu_array * 2)).all()\n\nnp.True_\n\n\n\n\nLooks like it worked! Tomorrow, I’ll try it with C++.",
    "crumbs": [
      "Day 0 - playing with PyCUDA"
    ]
  },
  {
    "objectID": "day_04_matmul.html",
    "href": "day_04_matmul.html",
    "title": "Day 4 - Naive matmul+exercises",
    "section": "",
    "text": "import numpy as np\nfrom PIL import Image\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\nfrom pathlib import Path\n\n\ncu_file = \"kernels/matmul/matmul.cu\"\n\n\nNaive matmul kernels/matmul/matmul.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n__global__ void matmul_f32(float *m1, float *m2, float *res,\n    uint32_t out_shape_0,\n    uint32_t out_shape_1,\n    uint32_t inner_dim,\n    uint32_t ) {\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int m1_width = inner_dim;\n    int m2_width = out_shape_1;\n\n    double out;\n    if (x &lt; out_shape_1 && y &lt; out_shape_0) {\n        out = 0;\n        for (int i = 0; i &lt; inner_dim; i++) {\n            out += m1[y*m1_width + i] * m2[i*m2_width + x];\n        }\n        res[y*out_shape_1 + x] = out;\n    }\n}\n\n\n\n\nfrom lovely_numpy import Lo\n\n\nm1 = np.random.randn(100, 200).astype(np.float32)\nm2 = np.random.randn(200, 300).astype(np.float32)\n\nnp_res = np.matmul(m1, m2)\nLo(np_res)\n\narray[100, 300] f32 n=30000 (0.1Mb) x∈[-57.284, 65.644] μ=-0.102 σ=14.150\n\n\n\n\nTesting naive matnul\n\nBLOCK_SIZE_X = 32\nBLOCK_SIZE_Y = 32\n\nassert(len(m1.shape) == 2)\nassert(len(m2.shape) == 2)\nassert(m1.shape[1] == m2.shape[0])\n\nout_shape = (m1.shape[0], m2.shape[1])\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(cu_file).read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    matmul_f32 = mod.get_function(\"matmul_f32\")\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res = np.empty(out_shape, dtype=np.float32)\n\n    gpu_res = cuda.mem_alloc_like(res)\n\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n\n    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n    grid_size = (\n        ((out_shape[1] + BLOCK_SIZE_X - 1) // BLOCK_SIZE_X),\n        ((out_shape[0] + BLOCK_SIZE_Y - 1) // BLOCK_SIZE_Y),\n        1\n    )\n\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Restul dimensions: {out_shape[0]}x{out_shape[1]}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n    ctx.synchronize()\n\n    matmul_f32(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n\n    ctx.synchronize()\n\n    cuda.memcpy_dtoh(res, gpu_res)\n    ctx.synchronize()\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nLo(res)\n\nGrid size: (10, 4, 1)\nBlock size: (32, 32, 1)\nRestul dimensions: 100x300\nTotal threads: 40960\n\n\narray[100, 300] f32 n=30000 (0.1Mb) x∈[-57.284, 65.644] μ=-0.102 σ=14.150\n\n\n\nm1[0,1],m2[1,0]\n\n(np.float32(-0.9388011), np.float32(0.16297509))\n\n\n\nnp.isclose(res, np_res).all()\n\nnp.False_\n\n\n\nLo(np.isclose(res, np_res)).chans\n\n\n\n\n\n\n\n\n\n\nNunmeric stability\nLooks like matmul is very succeptible to numerical instability. &gt; Since we are adding numbers to the accumulator over and over, if the accumulated value gets large enough, &gt; it will lose precision to correctly accumulate small values. If it then gets a large update opposite of accumulated value &gt; and becomes small again, those errors will become very significant.\nBut I think overall it’s correct. I changed to accumulator to be double, and still seeting the discrepancy. It’s possible that numpy matmul also not not very precise.\n\n\nExercises\nLet’s do the exercises\n\nIn this chapter we implemented a matrix multiplication kernel that has each thread produce one output matrix element. In this question, you will implement different matrix-matrix multiplication kernels and compare them.\n\n\nWrite a kernel that has each thread produce one output matrix row. Fill in the execution configuration parameters for the design.\n\n\nWrite a kernel that has each thread produce one output matrix column. Fill in the execution configuration parameters for the design.\n\n\nAnalyze the pros and cons of each of the two kernel designs.\n\n\n\n\ncu_file2 = \"kernels/matmul/matmul-row_col.cu\"\n\nOne thread per row/col:\n\n\nNaive matmul row/col kernels/matmul/matmul-row_col.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n__global__ void matmul_f32(float* m1, float* m2, float* res,\n                           uint32_t out_shape_0,\n                           uint32_t out_shape_1,\n                           uint32_t inner_dim)\n{\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int m1_width = inner_dim;\n    int m2_width = out_shape_1;\n\n    double out;\n    if (x &lt; out_shape_1 && y &lt; out_shape_0) {\n        out = 0;\n        for (int i = 0; i &lt; inner_dim; i++) {\n            out += m1[y * m1_width + i] * m2[i * m2_width + x];\n        }\n        res[y * out_shape_1 + x] = out;\n    }\n}\n\n__global__ void matmul_f32_row(float* m1, float* m2, float* res,\n                               uint32_t out_shape_0,\n                               uint32_t out_shape_1,\n                               uint32_t inner_dim,\n                               uint32_t)\n\n{\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int m1_width = inner_dim;\n    int m2_width = out_shape_1;\n\n    if (y &lt; out_shape_0) {\n        for (int x = 0; x &lt; out_shape_1; x++) {\n            double out = 0;\n            for (int i = 0; i &lt; inner_dim; i++) {\n                out += m1[y * m1_width + i] * m2[i * m2_width + x];\n            }\n            res[y * out_shape_1 + x] = out;\n        }\n    }\n\n}\n\n__global__ void matmul_f32_col(float* m1, float* m2, float* res,\n                               uint32_t out_shape_0,\n                               uint32_t out_shape_1,\n                               uint32_t inner_dim,\n                               uint32_t)\n{\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int m1_width = inner_dim;\n    int m2_width = out_shape_1;\n\n    if (x &lt; out_shape_1) {\n        for (int y = 0; y &lt; out_shape_1; y++) {\n            double out = 0;\n            for (int i = 0; i &lt; inner_dim; i++) {\n                out += m1[y * m1_width + i] * m2[i * m2_width + x];\n            }\n            res[y * out_shape_1 + x] = out;\n        }\n    }\n}\n\n\n\nTesting the thread per row matmul\n\nBLOCK_SIZE_X = 1\nBLOCK_SIZE_Y = 32\n\nassert(len(m1.shape) == 2)\nassert(len(m2.shape) == 2)\nassert(m1.shape[1] == m2.shape[0])\n\nout_shape = (m1.shape[0], m2.shape[1])\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(cu_file2).read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    matmul_f32_row = mod.get_function(\"matmul_f32_row\")\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res_row = np.empty(out_shape, dtype=np.float32)\n\n    gpu_res_row = cuda.mem_alloc_like(res_row)\n\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n\n    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n    grid_size = (1, ((out_shape[0] + BLOCK_SIZE_Y - 1) // BLOCK_SIZE_Y), 1)\n\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Restul dimensions: {out_shape[0]}x{out_shape[1]}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n    ctx.synchronize()\n\n    matmul_f32_row(gpu_m1, gpu_m2, gpu_res_row, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n    # ctx.synchronize()\n\n    cuda.memcpy_dtoh(res_row, gpu_res_row)\n    ctx.synchronize()\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nLo(res_row)\n\nGrid size: (1, 4, 1)\nBlock size: (1, 32, 1)\nRestul dimensions: 100x300\nTotal threads: 128\n\n\narray[100, 300] f32 n=30000 (0.1Mb) x∈[-57.284, 65.644] μ=-0.102 σ=14.150\n\n\n\nLo(res)\n\narray[100, 300] f32 n=30000 (0.1Mb) x∈[-57.284, 65.644] μ=-0.102 σ=14.150\n\n\n\n(res == res_row).all()\n\nnp.True_\n\n\n\n\nTesting one thread per col matnul\n\nBLOCK_SIZE_X = 32\nBLOCK_SIZE_Y = 1\n\nassert(len(m1.shape) == 2)\nassert(len(m2.shape) == 2)\nassert(m1.shape[1] == m2.shape[0])\n\nout_shape = (m1.shape[0], m2.shape[1])\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(Path(cu_file2).read_text(),\n        options=[\n            '-Xcompiler', '-Wall',\n            '-Xcompiler', '-Wextra',\n            '-Xcompiler', '-Wsign-conversion',\n            '-Xcompiler', '-Wcast-qual',\n            '-Xcompiler', '-Wunused-parameter',\n            '-Xcompiler', '-Wdouble-promotion',\n            '-Xcompiler', '-Wformat=2',\n            '-Xcompiler', '-Wfloat-equal',\n            '-Xcompiler', '-Wshadow'\n        ]\n        )\n\n    matmul_f32_col = mod.get_function(\"matmul_f32_col\")\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res_col = np.empty(out_shape, dtype=np.float32)\n\n    gpu_res_col = cuda.mem_alloc_like(res_col)\n\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n\n    block_size = (BLOCK_SIZE_X, BLOCK_SIZE_Y, 1)\n    grid_size = (((out_shape[1] + BLOCK_SIZE_X - 1) // BLOCK_SIZE_X),1,1)\n\n    print(f\"Grid size: {grid_size}\")\n    print(f\"Block size: {block_size}\")\n    print(f\"Restul dimensions: {out_shape[0]}x{out_shape[1]}\")\n    print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n    ctx.synchronize()\n\n    matmul_f32_col(gpu_m1, gpu_m2, gpu_res_col, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n    ctx.synchronize()\n\n    cuda.memcpy_dtoh(res_col, gpu_res_col)\n    ctx.synchronize()\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nLo(res_col)\n\nGrid size: (10, 1, 1)\nBlock size: (32, 1, 1)\nRestul dimensions: 100x300\nTotal threads: 320\n\n\narray[100, 300] f32 n=30000 (0.1Mb) x∈[-57.284, 65.644] μ=-0.102 σ=14.150\n\n\n\n(res_col == res).all()\n\nnp.True_\n\n\n\n\nAnalyze the pros and cons of each of the two kernel designs.\n\n\nThey both suck, but because we are not using enough threads to saturate the GPU.\nRow possibly sucks less because the cache is shared between thread blocks.",
    "crumbs": [
      "Day 4 - Naive matmul+exercises"
    ]
  },
  {
    "objectID": "day_11_conv2d-shared.html",
    "href": "day_11_conv2d-shared.html",
    "title": "Day 11 - conv2d with shared memory",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom math import prod\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\n\nfrom lovely_numpy import Lo\nfrom lovely_tensors import monkey_patch; monkey_patch()\nfrom torch import Tensor\nfrom torch.nn.functional import conv2d\n\nimport warn_options\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file=\"kernels/conv2d/conv2d-z-out-shared.cu\"\n\n\nkernels/conv2d/conv2d-z-out-shared.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n#include \"conv2d-helpers.h\"\n\n// This version copies each input channel into shared memory before performing the\n// convolution. Grid Z is used for output channels, so each thread only handles one\n// output channel\n__global__ void conv2d_pad_z_out_shared(float *in,\n                                        float *out,\n                                        float *filter,\n                                        int h,\n                                        int w,\n                                        int in_channels,\n                                        int out_channels,\n                                        int filter_size /* Must be an odd number */,\n                                        float pad) {\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int out_ch = blockIdx.z;\n\n    int filter_r = (filter_size - 1) / 2;\n\n    extern __shared__ float cell[];\n\n    // In and Out data dimensions:\n    // 0 - channel\n    // 1 - height\n    // 2 - width\n\n    // Filter dimensions:\n    // 0 - out channels\n    // 1 - in channels\n    // 2 - height\n    // 3 - width\n\n    if (x &gt;= w || y &gt;= h) return;\n\n#ifdef DEBUG\n    if (x == 0 && y == 0) PRINT_INPUTS();\n#endif\n\n    // Loop over the output channels\n\n    // // Pointer to the 2d slice of the output\n\n    float *sub_output = out + out_ch * w * h;\n    ACCUM_DTYPE R = 0;\n    // Loop over the input channels\n    for (int in_c = 0; in_c &lt; in_channels; in_c++) {\n        // Pointer to the 2d slice of the filter that corresponds to the active input and output\n        // channels\n        float *sub_filter = filter + (filter_size * filter_size * in_channels * out_ch) +\n                            (filter_size * filter_size * in_c);\n        // Pinter to the current channel in the input\n        float *sub_input = in + (w * h * in_c);\n\n        cell[threadIdx.y * blockDim.x + threadIdx.x] = sub_input[y * w + x];\n        __syncthreads();  // Wait for all threads to load the input\n\n        // Apply the filter to the input or the pad value for outside indices.\n        for (int filter_y = 0; filter_y &lt; filter_size; filter_y++) {\n            for (int filter_x = 0; filter_x &lt; filter_size; filter_x++) {\n                int tile_x = threadIdx.x - filter_r + filter_x;\n                int tile_y = threadIdx.y - filter_r + filter_y;\n\n                int input_x = x - filter_r + filter_x;\n                int input_y = y - filter_r + filter_y;\n\n                if (tile_x &gt;= 0 && tile_x &lt; blockDim.x && tile_y &gt;= 0 && tile_y &lt; blockDim.y) {\n                    R += cell[tile_y * blockDim.x + tile_x] *\n                         sub_filter[filter_y * filter_size + filter_x];\n                } else if (input_x &gt;= 0 && input_x &lt; w && input_y &gt;= 0 && input_y &lt; h) {\n                    R += sub_input[input_y * w + input_x] *\n                         sub_filter[filter_y * filter_size + filter_x];\n                } else {\n                    R += pad * sub_filter[filter_y * filter_size + filter_x];\n                }\n            }\n        }\n\n        __syncthreads();  // Wait for all threads to complete before we load the next input\n    }\n\n    sub_output[y * w + x] = R;\n}\n\n\ndef benchmark_conv2d_pad(ctx, kernel, input, filter, pad, block_size, grid_size, shared=None, repeat=10, warmup=True):\n    # input, channel-first\n    # - Channel\n    # - Height\n    # - Width\n    assert len(input.shape) == 3\n\n    # Filter shape should be\n    # - Out channels\n    # - In  channels\n    # - Height\n    # - Width\n    assert len(filter.shape) == 4\n\n    in_ch, h, w = input.shape\n    out_ch, in_ch2, fh, fw = filter.shape\n\n    assert fh == fw, f\"Only square filters supported, got shape={filter.shape}\"\n\n    assert in_ch == in_ch2\n\n    out_shape = (out_ch, h, w)\n    # print(f\"shared = {shared}\")\n    # print(f\"out_shape={out_shape}\")\n\n    gpu_input = cuda.mem_alloc_like(input)\n    gpu_filter = cuda.mem_alloc_like(filter)\n\n    out = np.empty(out_shape, dtype=np.float32)\n\n    cuda.memcpy_htod(gpu_input, input)\n    cuda.memcpy_htod(gpu_filter, filter)\n    ctx.synchronize()\n\n    timing=0\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n        gpu_out = cuda.mem_alloc_like(out)\n\n        if warmup:\n            kernel(gpu_input, gpu_out, gpu_filter,\n                   np.int32(h),\n                   np.int32(w),\n                   np.int32(in_ch),\n                   np.int32(out_ch),\n                   np.int32(fh),\n                   np.float32(pad),\n                   grid=grid_size,\n                   block=block_size,\n                   shared=shared\n                   )\n            ctx.synchronize()\n\n        start.record()\n        kernel(gpu_input, gpu_out, gpu_filter,\n               np.int32(h),\n               np.int32(w),\n               np.int32(in_ch),\n               np.int32(out_ch),\n               np.int32(fh),\n               np.float32(pad),\n               grid=grid_size,\n               block=block_size,\n               shared=shared\n               )\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n\n    cuda.memcpy_dtoh(out, gpu_out)\n    return out, timing;\n\n\nin_chan_range = [1, 3, 8, 32, 128, 512]\nout_chan_range = [1, 4, 8, 32, 128, 512]\n\nfilter_size = [1, 3, 5]\n\nimg_size_range = [64, 128, 256, 512, 1024]\n\n# Let's sample from the available options.\nn_samples = 50\n\n\n# Generate all possible combinations\ncombinations = []\nfor in_ch in in_chan_range:\n    for out_ch in out_chan_range:\n        for fs in filter_size:\n            for img_size in img_size_range:\n                    n = in_ch * out_ch * img_size * img_size\n\n                    # Skip combinatoins that are too large\n                    if n &lt; 1024*1024*32*32:\n                        combinations.append((in_ch, out_ch, fs, img_size))\n\nn_samples = min(n_samples, len(combinations))\nsampled_combinations = np.random.choice(len(combinations), size=n_samples, replace=False)\ntest_cases = [combinations[i] for i in sampled_combinations]\n\n\ntile_width = 32\n\ndata = []\n\n# test_cases = [(512, 8, 9, 64)]\n\nctx = device.make_context()\ntry:\n    mod = SourceModule(\n        Path(cu_file).read_text(),\n        options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\"],\n        include_dirs=[str(Path(cu_file).parent.absolute())]\n    )\n\n    mod_z_out = SourceModule(\n        Path(\"kernels/conv2d/conv2d-z-out.cu\").read_text(),\n        options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\"],\n        include_dirs=[str(Path(cu_file).parent.absolute())]\n    )\n\n    mod_naive = SourceModule(\n        Path(\"kernels/conv2d/conv2d_naive.cu\").read_text(),\n        options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\"],\n        include_dirs=[str(Path(cu_file).parent.absolute())]\n    )\n\n    kernels = {\n        \"conv2d_pad_z_out_shared\": mod.get_function(\"conv2d_pad_z_out_shared\"),\n        \"conv2d_pad\": mod_naive.get_function(\"conv2d_pad\"),\n        \"conv2d_pad_z_out\": mod_z_out.get_function(\"conv2d_pad_z_out\")\n    }\n\n    for tc in tqdm(test_cases):\n        ch_in, ch_out, fs, pixels = tc\n\n        array_in = np.random.randn(ch_in, pixels, pixels).astype(np.float32)\n        filter = np.random.randn(ch_out, ch_in, fs, fs).astype(np.float32)\n\n        torch_out = conv2d(Tensor(array_in), Tensor(filter), padding=\"same\")\n\n        timings = {}\n\n        for kernel_name, kernel in kernels.items():\n\n            block_size = (tile_width, tile_width, 1)\n            grid_size = (((pixels+tile_width-1) // tile_width), ((pixels+tile_width-1) // tile_width),\n                         1 if kernel_name == \"conv2d_pad\" else ch_out)\n\n            out, timing = benchmark_conv2d_pad(\n                ctx=ctx,\n                kernel=kernel,\n                input=array_in,\n                filter=filter,\n                pad=0,\n                block_size=block_size,\n                grid_size=grid_size,\n                shared=tile_width * tile_width * 4 if kernel_name == \"conv2d_pad_z_out_shared\" else 0,\n                repeat=5,\n                warmup=True\n            )\n\n            if np.isclose(out, torch_out).mean() &lt; 0.8:\n                print(\"### Result mismatch ###\")\n                print(f\"Kernel: {kernel_name}\")\n                print(f\"Input shape: {array_in.shape}\")\n                print(f\"Filter shape: {filter.shape}\")\n                print(f\"Result shape: {(filter.shape[0], array_in.shape[1], array_in.shape[2])}\")\n                print(f\"Grid size: {grid_size}\")\n                print(f\"Block size: {block_size}\")\n                print(f\"Total threads: {prod((*grid_size, *block_size))}\")\n\n            timings[kernel_name] = timing\n            # time.sleep(10)\n\n        data.append({\n            'in_ch': ch_in,\n            'out_ch': ch_out,\n            'filter_size': fs,\n            'img_size': pixels,\n            # 'kernel': kernel_name,\n        } | timings)\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\nresults = pd.DataFrame(data)\n\n\n\n\n\n\nResults\n\n# Sort by conv2d_pad timing\nresults_sorted = results.sort_values(by='conv2d_pad')\n\n# Create a plot comparing the two kernels\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Create labels for x-axis that include dimensions\nresults_sorted['dimensions'] = results_sorted.apply(\n    lambda row: f\"{int(row['img_size'])}×{int(row['img_size'])}×{int(row['in_ch'])} -&gt; {int(row['out_ch'])}, f:{int(row['filter_size'])}×{int(row['filter_size'])}\",\n    axis=1\n)\n\n# Melt the dataframe to get it in the right format for seaborn\nmelted_results = pd.melt(\n    results_sorted,\n    id_vars=['in_ch', 'out_ch', 'filter_size', 'img_size', 'dimensions'],\n    value_vars=['conv2d_pad', 'conv2d_pad_z_out', 'conv2d_pad_z_out_shared'],\n    var_name='kernel',\n    value_name='time'\n)\n\n# Split the data into two halves based on timing\nmidpoint = len(results_sorted) // 2\nfaster_results = melted_results[melted_results['dimensions'].isin(results_sorted['dimensions'][:midpoint])]\nslower_results = melted_results[melted_results['dimensions'].isin(results_sorted['dimensions'][midpoint:])]\n\n# Create a figure with two subplots\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n\n# Plot faster results in the first subplot\nsns.barplot(x='dimensions', y='time', hue='kernel', data=faster_results, ax=ax1)\nax1.set_xlabel('')\nax1.set_ylabel('Time (ms)')\nax1.set_title('Performance Comparison - Faster Results')\nax1.tick_params(axis='x', rotation=90)\nax1.legend(title='Kernel')\n\n# Plot slower results in the second subplot\nsns.barplot(x='dimensions', y='time', hue='kernel', data=slower_results, ax=ax2)\nax2.set_xlabel('Input and Filter Dimensions')\nax2.set_ylabel('Time (ms)')\nax2.set_title('Performance Comparison - Slower Results')\nax2.tick_params(axis='x', rotation=90)\nax2.legend(title='Kernel')\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n# Also display the sorted results table\nresults_sorted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nin_ch\nout_ch\nfilter_size\nimg_size\nconv2d_pad_z_out_shared\nconv2d_pad\nconv2d_pad_z_out\ndimensions\n\n\n\n\n18\n1\n4\n1\n128\n0.015974\n0.014950\n0.014336\n128×128×1 -&gt; 4, f:1×1\n\n\n47\n1\n1\n3\n64\n0.016794\n0.018637\n0.014541\n64×64×1 -&gt; 1, f:3×3\n\n\n21\n3\n1\n3\n256\n0.037274\n0.027034\n0.025805\n256×256×3 -&gt; 1, f:3×3\n\n\n23\n1\n8\n3\n64\n0.022733\n0.033587\n0.020480\n64×64×1 -&gt; 8, f:3×3\n\n\n43\n3\n8\n3\n64\n0.025395\n0.058573\n0.019866\n64×64×3 -&gt; 8, f:3×3\n\n\n13\n3\n1\n3\n512\n0.092570\n0.058778\n0.058163\n512×512×3 -&gt; 1, f:3×3\n\n\n12\n32\n1\n1\n256\n0.106086\n0.062259\n0.064922\n256×256×32 -&gt; 1, f:1×1\n\n\n24\n1\n4\n3\n512\n0.120627\n0.073114\n0.084378\n512×512×1 -&gt; 4, f:3×3\n\n\n30\n1\n32\n3\n64\n0.030106\n0.080077\n0.109363\n64×64×1 -&gt; 32, f:3×3\n\n\n33\n32\n4\n1\n128\n0.085811\n0.086221\n0.056525\n128×128×32 -&gt; 4, f:1×1\n\n\n48\n3\n32\n1\n256\n0.186368\n0.126362\n0.129638\n256×256×3 -&gt; 32, f:1×1\n\n\n20\n1\n32\n5\n128\n0.128205\n0.169984\n0.084173\n128×128×1 -&gt; 32, f:5×5\n\n\n0\n1\n128\n1\n128\n0.093184\n0.192512\n0.073523\n128×128×1 -&gt; 128, f:1×1\n\n\n26\n3\n128\n1\n128\n0.180838\n0.233882\n0.126566\n128×128×3 -&gt; 128, f:1×1\n\n\n16\n1\n512\n1\n128\n0.319693\n0.369664\n0.244326\n128×128×1 -&gt; 512, f:1×1\n\n\n14\n8\n4\n3\n512\n0.820224\n0.403046\n0.499302\n512×512×8 -&gt; 4, f:3×3\n\n\n34\n32\n32\n1\n128\n0.395059\n0.556237\n0.237363\n128×128×32 -&gt; 32, f:1×1\n\n\n32\n3\n128\n3\n64\n0.141722\n0.725811\n0.089702\n64×64×3 -&gt; 128, f:3×3\n\n\n44\n512\n1\n1\n256\n1.329971\n0.743629\n0.754483\n256×256×512 -&gt; 1, f:1×1\n\n\n37\n8\n8\n1\n1024\n1.926963\n0.826368\n1.283072\n1024×1024×8 -&gt; 8, f:1×1\n\n\n25\n8\n4\n5\n512\n1.817190\n0.915046\n0.969114\n512×512×8 -&gt; 4, f:5×5\n\n\n38\n32\n32\n1\n256\n1.848525\n1.133158\n1.107354\n256×256×32 -&gt; 32, f:1×1\n\n\n1\n3\n32\n1\n1024\n3.284378\n1.242317\n2.644992\n1024×1024×3 -&gt; 32, f:1×1\n\n\n22\n1\n128\n5\n256\n1.764147\n1.248870\n1.013350\n256×256×1 -&gt; 128, f:5×5\n\n\n3\n512\n1\n3\n64\n2.400461\n1.253990\n1.257882\n64×64×512 -&gt; 1, f:3×3\n\n\n28\n32\n8\n5\n128\n0.943514\n1.274675\n0.467763\n128×128×32 -&gt; 8, f:5×5\n\n\n45\n512\n1\n3\n128\n2.519245\n1.280614\n1.275904\n128×128×512 -&gt; 1, f:3×3\n\n\n7\n3\n128\n1\n512\n3.371622\n1.326080\n2.317722\n512×512×3 -&gt; 128, f:1×1\n\n\n17\n3\n512\n1\n256\n2.973082\n1.753088\n1.833779\n256×256×3 -&gt; 512, f:1×1\n\n\n41\n3\n128\n5\n64\n0.328909\n1.810022\n0.183296\n64×64×3 -&gt; 128, f:5×5\n\n\n9\n3\n128\n5\n128\n1.266893\n1.844634\n0.679117\n128×128×3 -&gt; 128, f:5×5\n\n\n15\n32\n4\n3\n512\n3.226624\n1.954816\n1.873306\n512×512×32 -&gt; 4, f:3×3\n\n\n40\n8\n512\n1\n64\n0.394240\n2.289254\n0.242483\n64×64×8 -&gt; 512, f:1×1\n\n\n49\n32\n8\n5\n256\n3.610214\n2.547712\n1.794867\n256×256×32 -&gt; 8, f:5×5\n\n\n8\n3\n8\n5\n1024\n5.853798\n2.647040\n3.288064\n1024×1024×3 -&gt; 8, f:5×5\n\n\n35\n512\n8\n1\n64\n0.688538\n2.897920\n0.348160\n64×64×512 -&gt; 8, f:1×1\n\n\n46\n128\n32\n1\n128\n1.876787\n3.093299\n0.982426\n128×128×128 -&gt; 32, f:1×1\n\n\n10\n1\n32\n5\n1024\n9.511936\n3.605504\n4.901683\n1024×1024×1 -&gt; 32, f:5×5\n\n\n29\n3\n32\n3\n1024\n11.349197\n4.278477\n6.614630\n1024×1024×3 -&gt; 32, f:3×3\n\n\n19\n8\n512\n1\n256\n6.478848\n4.831232\n4.056064\n256×256×8 -&gt; 512, f:1×1\n\n\n27\n32\n32\n5\n64\n0.920986\n5.430477\n0.462234\n64×64×32 -&gt; 32, f:5×5\n\n\n5\n128\n8\n5\n64\n1.239859\n5.528781\n0.618906\n64×64×128 -&gt; 8, f:5×5\n\n\n42\n1\n512\n3\n512\n14.623539\n6.328320\n9.598566\n512×512×1 -&gt; 512, f:3×3\n\n\n6\n8\n8\n5\n1024\n16.636518\n7.377920\n8.506163\n1024×1024×8 -&gt; 8, f:5×5\n\n\n39\n32\n512\n1\n128\n6.386483\n9.455616\n3.391898\n128×128×32 -&gt; 512, f:1×1\n\n\n36\n32\n128\n3\n128\n5.712077\n9.837773\n3.195904\n128×128×32 -&gt; 128, f:3×3\n\n\n4\n32\n128\n3\n256\n27.863654\n22.527795\n15.678259\n256×256×32 -&gt; 128, f:3×3\n\n\n31\n512\n8\n5\n128\n17.193369\n26.259456\n7.303168\n128×128×512 -&gt; 8, f:5×5\n\n\n2\n32\n512\n3\n64\n5.996749\n38.739558\n3.200000\n64×64×32 -&gt; 512, f:3×3\n\n\n11\n512\n4\n5\n512\n134.970367\n81.715004\n68.868095\n512×512×512 -&gt; 4, f:5×5\n\n\n\n\n\n\n\nFor some reason, the version with shared memory is actually slower. Not entirely sure why, because it looks correct",
    "crumbs": [
      "Day 11 - conv2d with shared memory"
    ]
  },
  {
    "objectID": "day_07_matmul-tiled-experiments.html",
    "href": "day_07_matmul-tiled-experiments.html",
    "title": "Day 7 - Tiled matmul experiments",
    "section": "",
    "text": "Benchmark it against Numpy and naive matmul\nBenchmark the impact of boundary checks on performance.\n\n\n\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\n\n\nimport pycuda.driver as cuda\nfrom pycuda.compiler import SourceModule\ncuda.init()\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file=\"kernels/matmul/matmul-tiled-experiments.cu\"\n\n\nkernels/matmul/matmul-tiled-experiments.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n\n#ifndef TILE_WIDTH\n#define TILE_WIDTH 16\n#endif\n\n__global__ void matmul_fp32_tiled_bc(float* m1, float* m2, float* res,\n                                     uint32_t out_shape_0,\n                                     uint32_t out_shape_1,\n                                     uint32_t inner_dim,\n                                     uint32_t) {\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    __shared__ float m1_tile[TILE_WIDTH][TILE_WIDTH];\n    __shared__ float m2_tile[TILE_WIDTH][TILE_WIDTH];\n\n\n    int m1_x = inner_dim;\n    int m2_x = out_shape_1;\n\n    if (x &lt; out_shape_1 && y &lt; out_shape_0) {\n        float R = 0;\n        for (int tile = 0; tile &lt; inner_dim / TILE_WIDTH; tile++) {\n\n            m1_tile[threadIdx.y][threadIdx.x] = m1[y * m1_x + tile * TILE_WIDTH + threadIdx.x];\n            m2_tile[threadIdx.y][threadIdx.x] = m2[(tile * TILE_WIDTH + threadIdx.y) * m2_x + x];\n\n            __syncthreads();\n\n            for (int i = 0; i &lt; TILE_WIDTH; i++) {\n                R += m1_tile[threadIdx.y][i] * m2_tile[i][threadIdx.x];\n            }\n\n            __syncthreads();\n        }\n\n        res[y * out_shape_1 + x] = R;\n    }\n\n}\n\n__global__ void matmul_fp32_tiled(float* m1, float* m2, float* res,\n                                     uint32_t out_shape_0,\n                                     uint32_t out_shape_1,\n                                     uint32_t inner_dim,\n                                     uint32_t) {\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    __shared__ float m1_tile[TILE_WIDTH][TILE_WIDTH];\n    __shared__ float m2_tile[TILE_WIDTH][TILE_WIDTH];\n\n\n    int m1_x = inner_dim;\n    int m2_x = out_shape_1;\n\n    float R = 0;\n    for (int tile = 0; tile &lt; inner_dim / TILE_WIDTH; tile++) {\n\n        m1_tile[threadIdx.y][threadIdx.x] = m1[y * m1_x + tile * TILE_WIDTH + threadIdx.x];\n        m2_tile[threadIdx.y][threadIdx.x] = m2[(tile * TILE_WIDTH + threadIdx.y) * m2_x + x];\n\n        __syncthreads();\n\n        for (int i = 0; i &lt; TILE_WIDTH; i++) {\n            R += m1_tile[threadIdx.y][i] * m2_tile[i][threadIdx.x];\n        }\n\n        __syncthreads();\n    }\n\n    res[y * out_shape_1 + x] = R;\n\n}\n\n\n\n\n// Non-tiled version\n__global__ void matmul_fp32(float* m1, float* m2, float* res,\n                            uint32_t out_shape_0,\n                            uint32_t out_shape_1,\n                            uint32_t inner_dim,\n                            uint32_t) {\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int m1_width = inner_dim;\n    int m2_width = out_shape_1;\n\n    float out;\n    if (x &lt; out_shape_1 && y &lt; out_shape_0) {\n        out = 0;\n        for (int i = 0; i &lt; inner_dim; i++) {\n            out += m1[y * m1_width + i] * m2[i * m2_width + x];\n        }\n        res[y * out_shape_1 + x] = out;\n    }\n}\n\n\n\n\nfrom lovely_numpy import Lo\n\n\nm1 = np.random.randn(513, 1024).astype(np.float32)\nm2 = np.random.randn(1024, 8000).astype(np.float32)\n\nnp_res = np.matmul(m1, m2)\nLo(np_res)\n\narray[513, 8000] f32 n=4104000 (16Mb) x∈[-170.506, 157.441] μ=0.035 σ=31.994\n\n\n\n## Compiler options for more compile-time warnings.\nwarn_options=[\n    '-Xcompiler', '-Wall',\n    '-Xcompiler', '-Wextra',\n    '-Xcompiler', '-Wsign-conversion',\n    '-Xcompiler', '-Wcast-qual',\n    '-Xcompiler', '-Wunused-parameter',\n    '-Xcompiler', '-Wdouble-promotion',\n    '-Xcompiler', '-Wformat=2',\n    '-Xcompiler', '-Wfloat-equal',\n    '-Xcompiler', '-Wshadow'\n]\n\n\ndef benchmark_matmul(file, kernel_name, m1, m2, tile_width=16, repeat=100):\n\n    assert len(m1.shape) == 2\n    assert len(m2.shape) == 2\n    assert m1.shape[1] == m2.shape[0]\n\n    out_shape = (m1.shape[0], m2.shape[1])\n\n    try:\n        ctx = device.make_context()\n\n        mod = SourceModule(\n            Path(file).read_text(),\n            options=warn_options + [\n                f\"-D TILE_WIDTH={tile_width}\",\n                ])\n\n        kernel = mod.get_function(kernel_name)\n\n        gpu_m1 = cuda.mem_alloc_like(m1)\n        gpu_m2 = cuda.mem_alloc_like(m2)\n\n        res = np.empty(out_shape, dtype=np.float32)\n\n        cuda.memcpy_htod(gpu_m1, m1)\n        cuda.memcpy_htod(gpu_m2, m2)\n\n        block_size = (tile_width, tile_width, 1)\n        grid_size = (\n            ((out_shape[1] + tile_width - 1) // tile_width),\n            ((out_shape[0] + tile_width - 1) // tile_width),\n            1\n        )\n\n\n        print(f\"Matrix 1 shape: {m1.shape}\")\n        print(f\"Matrix 2 shape: {m2.shape}\")\n        print(f\"Result shape: {out_shape}\")\n        print(f\"Grid size: {grid_size}\")\n        print(f\"Block size: {block_size}\")\n        print(f\"Total threads: {grid_size[0] * grid_size[1] * block_size[0] * block_size[1]}\")\n\n\n        ctx.synchronize()\n\n        timing=0\n        for _ in range(repeat):\n            start = cuda.Event()\n            end = cuda.Event()\n\n            gpu_res = cuda.mem_alloc_like(res)\n\n            kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n\n            start.record()\n            kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n            end.record()\n\n            cuda.memcpy_dtoh(res, gpu_res)\n\n            timing += end.time_since(start)\n        timing /= repeat\n\n\n    finally:\n        ctx.pop()\n        ctx.detach()\n    return res, timing\n\n\nres, timing = benchmark_matmul(cu_file, \"matmul_fp32_tiled_bc\", m1, m2, 16, repeat=10)\nprint(Lo(res))\nprint(f\"Took {timing:.3f}ms\")\n\nMatrix 1 shape: (513, 1024)\nMatrix 2 shape: (1024, 8000)\nResult shape: (513, 8000)\nGrid size: (500, 33, 1)\nBlock size: (16, 16, 1)\nTotal threads: 4224000\narray[513, 8000] f32 n=4104000 (16Mb) x∈[-170.506, 157.441] μ=0.032 σ=31.975\nTook 9.715ms\n\n\n\nnp.isclose(res, np_res).mean()\n\nnp.float64(0.9766790935672515)\n\n\n\n\nExperiment with tile width\n\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n\nimport random\n\n\ndata = []\n\nrepeat = 3\n\ndef time_kernel(ctx, kernel, tile_size, matrix_size, repeat=5):\n    out_shape = (matrix_size, matrix_size)\n\n    m1 = np.random.randn(matrix_size, matrix_size).astype(np.float32)\n    m2 = np.random.randn(matrix_size, matrix_size).astype(np.float32)\n\n    res = np.empty_like(m1)\n\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    gpu_res = cuda.mem_alloc_like(res)\n\n    block_size = (tile_size, tile_size, 1)\n    grid_size = (\n        ((out_shape[1] + tile_size - 1) // tile_size),\n        ((out_shape[0] + tile_size - 1) // tile_size),\n        1\n    )\n\n    # warmup run, just in case\n    kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n\n\n    timing = 0\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n\n        start.record()\n        kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n\n    return timing\n\n\n\n# for tile_size in tqdm([32, 24, 16, 12, 8, 4]):\nfor tile_size in tqdm([4, 8, 16, 32]):\n    ctx = device.make_context()\n\n    mod = SourceModule(\n        Path(cu_file).read_text(),\n        options=warn_options + [\n            f\"-D TILE_WIDTH={tile_size}\"\n            ])\n\n    kernel_bc = mod.get_function(\"matmul_fp32_tiled_bc\")\n    kernel_nc = mod.get_function(\"matmul_fp32_tiled\")\n\n\n    n = 0\n\n    for matrix_size in tqdm(range(64,8192, 32)):\n        timing = time_kernel(ctx, kernel_nc, tile_size, matrix_size, repeat)\n\n        data.append({\n            \"matrix_size\": matrix_size,\n            \"tile_size\": tile_size,\n            \"timing_nc\": timing\n        })\n\n        n += 1\n        if timing &gt; 300: break # We increase the size of the matrix until it gets too slow\n\n    # Sample a few matrix sizes that are not multiple of tile size\n    for _ in tqdm(range(n)):\n\n        # Generate a random matrix size that is not multiple of tile size\n        matrix_size = 32\n        while not matrix_size % tile_size:\n            matrix_size = random.randint(1, n*32)\n\n        timing = time_kernel(ctx, kernel_bc, tile_size, matrix_size, repeat)\n\n        data.append({\n            \"matrix_size\": matrix_size,\n            \"tile_size\": tile_size,\n            \"timing_bc\": timing\n        })\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s also time the naive matmul implementation\n\ndef time_naive_matmul(ctx, kernel, size, repeat=5):\n\n    BLOCK_SIZE=32\n\n    out_shape = (size, size)\n\n    m1 = np.random.randn(matrix_size, matrix_size).astype(np.float32)\n    m2 = np.random.randn(matrix_size, matrix_size).astype(np.float32)\n\n    gpu_m1 = cuda.mem_alloc_like(m1)\n    gpu_m2 = cuda.mem_alloc_like(m2)\n\n    res = np.empty(out_shape, dtype=np.float32)\n\n    gpu_res = cuda.mem_alloc_like(res)\n\n\n    cuda.memcpy_htod(gpu_m1, m1)\n    cuda.memcpy_htod(gpu_m2, m2)\n\n    block_size = (BLOCK_SIZE, BLOCK_SIZE, 1)\n    grid_size = (\n        ((out_shape[1] + BLOCK_SIZE - 1) // BLOCK_SIZE),\n        ((out_shape[0] + BLOCK_SIZE - 1) // BLOCK_SIZE),\n        1\n    )\n    # warmup run, just in case\n    kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n\n\n    timing = 0\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n\n        start.record()\n        kernel(gpu_m1, gpu_m2, gpu_res, np.uint32(out_shape[0]), np.uint32(out_shape[1]), np.uint32(m1.shape[1]), grid=grid_size, block=block_size)\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n    return timing\n\n\nnaive_d = []\n\ntry:\n    ctx = device.make_context()\n\n    mod = SourceModule(\n        Path(\"kernels/matmul/matmul.cu\").read_text(),\n        options=warn_options)\n\n    kernel = mod.get_function(\"matmul_f32\")\n\n    for matrix_size in tqdm(range(64, 8192, 32)):\n\n        timing = time_naive_matmul(ctx, kernel, matrix_size)\n\n        naive_d.append({\n            \"matrix_size\": matrix_size,\n            \"timing_nc\": timing\n        })\n\n\nfinally:\n    ctx.pop()\n    ctx.detach()\n\n\n\n\n\nimport time\n\n# Benchmark against numpy\nnumpy_data = []\n\nfor matrix_size in tqdm(range(64, 8192, 32)):\n    # Create random matrices\n    m1 = np.random.randn(matrix_size, matrix_size).astype(np.float32)\n    m2 = np.random.randn(matrix_size, matrix_size).astype(np.float32)\n\n    # Time numpy matmul\n    timing = 0\n    repeat = 3\n    for _ in range(repeat):\n        start_time = time.perf_counter()\n        np.matmul(m1, m2)\n        end_time = time.perf_counter()\n        timing += (end_time - start_time) * 1000  # Convert to ms\n    timing /= repeat\n\n    numpy_data.append({\n        \"matrix_size\": matrix_size,\n        \"timing_numpy\": timing\n    })\n\n\n\n\n\n# data = [d for d in data if \"tile_size\" in d]\n\n\n# naive_d = [{\n#     \"matrix_size\": matrix_size,\n#     \"timing_nc\": timing\n# } for matrix_size, timing in naive_d.items()]\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[21], line 4\n      1 naive_d = [{\n      2     \"matrix_size\": matrix_size,\n      3     \"timing_nc\": timing\n----&gt; 4 } for matrix_size, timing in naive_d.items()]\n\nAttributeError: 'list' object has no attribute 'items'\n\n\n\n\n# Create empty dataframe with matrix size as index\ndf = pd.DataFrame(index=sorted(list(set(d['matrix_size'] for d in data))))\n\n# Add columns for each tile size and version\nfor tile_size in [4, 8, 16, 32]:\n    # Get data for this tile size\n    tile_data = [d for d in data if d['tile_size'] == tile_size]\n\n    # Add bounds check timings\n    bc_data = {d['matrix_size']: d['timing_bc'] for d in tile_data if 'timing_bc' in d}\n    df[f'tile_{tile_size}_bc'] = pd.Series(bc_data)\n\n    # Add no bounds check timings\n    nc_data = {d['matrix_size']: d['timing_nc'] for d in tile_data if 'timing_nc' in d}\n    df[f'tile_{tile_size}_nc'] = pd.Series(nc_data)\n\n# Add naive matmul timings\nnaive_timing_data = {d['matrix_size']: d['timing_nc'] for d in naive_d}\ndf['naive'] = pd.Series(naive_timing_data)\n\n# Add numpy timings\nnumpy_timing_data = {d['matrix_size']: d['timing_numpy'] for d in numpy_data}\ndf['numpy'] = pd.Series(numpy_timing_data)\n\n\ndf\n\n\n\n\n\n\n\n\ntile_4_bc\ntile_4_nc\ntile_8_bc\ntile_8_nc\ntile_16_bc\ntile_16_nc\ntile_32_bc\ntile_32_nc\nnaive\nnumpy\n\n\n\n\n21\nNaN\nNaN\n0.009899\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n26\nNaN\nNaN\n0.013995\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n27\n0.016725\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n30\nNaN\nNaN\n0.020821\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n36\nNaN\nNaN\nNaN\nNaN\n0.017408\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4992\nNaN\nNaN\nNaN\nNaN\nNaN\n281.592153\nNaN\n296.357890\n376.128101\n484.159823\n\n\n5024\nNaN\nNaN\nNaN\nNaN\nNaN\n285.978963\nNaN\n302.391296\n390.056757\n491.502393\n\n\n5056\nNaN\nNaN\nNaN\nNaN\nNaN\n291.479889\nNaN\nNaN\n397.113953\n491.477690\n\n\n5088\nNaN\nNaN\nNaN\nNaN\nNaN\n299.429545\nNaN\nNaN\n404.441296\n510.304571\n\n\n5120\nNaN\nNaN\nNaN\nNaN\nNaN\n305.284444\nNaN\nNaN\n408.023248\n515.306334\n\n\n\n\n668 rows × 10 columns\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Create figure\nplt.figure(figsize=(16, 12))\n\n# Define colors for each tile size - darker shade for bc, lighter for nc\ncolors = {\n    32: ['#990000', '#ff6666'],  # Dark/light red\n    16: ['#006600', '#66ff66'],  # Dark/light green\n    8: ['#000099', '#6666ff'],   # Dark/light blue\n    4: ['#660066', '#ff66ff']    # Dark/light purple\n}\n\n# Plot for each tile size in reverse order so larger tiles appear first in legend\nfor tile_size in [32, 16, 8, 4]:\n    # Get data for this tile size from dataframe\n    bc_col = f'tile_{tile_size}_bc'\n    nc_col = f'tile_{tile_size}_nc'\n\n    # Get matrix sizes and timings, dropping NaN values\n    bc_data = df[bc_col].dropna()\n    nc_data = df[nc_col].dropna()\n    bc_matrix_sizes = bc_data.index\n    nc_matrix_sizes = nc_data.index\n\n    # Calculate GFLOPS\n    bc_gflops = (2 * bc_matrix_sizes**3 * 1000) / (bc_data * 1_000_000_000)\n    nc_gflops = (2 * nc_matrix_sizes**3 * 1000) / (nc_data * 1_000_000_000)\n\n    # Plot bounds check data\n    plt.scatter(bc_matrix_sizes, bc_gflops,\n               label=f'Bounds Check, Tile={tile_size}',\n               color=colors[tile_size][0],\n               s=16)\n\n    # Plot no bounds check data\n    plt.scatter(nc_matrix_sizes, nc_gflops,\n               label=f'No Bounds Check, Tile={tile_size}',\n               color=colors[tile_size][1],\n               s=16)\n\n# Get naive data and calculate GFLOPS\nnaive_d = df['naive'].dropna()\nnaive_matrix_sizes = naive_d.index\nnaive_gflops = (2 * naive_matrix_sizes**3 * 1000) / (naive_d * 1_000_000_000)\n\n# Plot naive data as a line\nplt.plot(naive_matrix_sizes, naive_gflops,\n         label='Naive Implementation',\n         color='gray',\n         linewidth=2)\n\n# Get numpy data and calculate GFLOPS\nnumpy_d = df['numpy'].dropna()\nnumpy_matrix_sizes = numpy_d.index\nnumpy_gflops = (2 * numpy_matrix_sizes**3 * 1000) / (numpy_d * 1_000_000_000)\n\n# Plot numpy data as a line\nplt.plot(numpy_matrix_sizes, numpy_gflops,\n         label='NumPy',\n         color='black',\n         linewidth=1)\n\nplt.title('Matrix Multiplication Performance vs Matrix Size')\nplt.xlabel('Matrix Size')\nplt.ylabel('Performance (GFLOPS)')\nplt.grid(True, color='lightgrey')\nplt.legend();",
    "crumbs": [
      "Day 7 - Tiled matmul experiments"
    ]
  },
  {
    "objectID": "day_12_conv2d-shared-halo.html",
    "href": "day_12_conv2d-shared-halo.html",
    "title": "Day 12 - conv2d with shared memory and halo",
    "section": "",
    "text": "import time\nimport pandas as pd\nimport numpy as np\nfrom math import prod\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\nimport warn_options\n\n\nfrom lovely_numpy import Lo\nfrom lovely_tensors import monkey_patch\n\nmonkey_patch()\nimport torch\nfrom torch import Tensor\nfrom torch.nn.functional import conv2d\n\n\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nfrom pycuda.compiler import SourceModule\n\ndevice = cuda.Device(0)\n\nprint(f\"Cuda version: {\".\".join([str(i) for i in cuda.get_version()])}\")\nprint(f\"Device:\\t{device.name()}\")\n\nCuda version: 12.8.0\nDevice: NVIDIA GeForce RTX 3080 Laptop GPU\n\n\n\ncu_file = \"kernels/conv2d/conv2d-z-out-shared-halo.cu\"\n\n\nkernels/conv2d/conv2d-z-out-shared-halo.cu\n\n#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\n#include \"conv2d-helpers.h\"\n\n/* In this version, we spawn extra threads to copy the tile into cache. */\n__global__ void conv2d_pad_z_out_shared_halo(\n    float *in,\n    float *out,\n    float *filter,\n    int h,\n    int w,\n    int in_channels,\n    int out_channels,\n    int filter_size /* Must be an odd number */,\n    float pad\n#ifdef SINGLE_BLOCK\n    ,\n    int *debug_counter /* This allows you to run the kernel one block at a time */\n#endif\n\n) {\n    int filter_r = (filter_size - 1) / 2;\n\n    int output_suze = TILE_SIZE - filter_size + 1;\n\n    int out_x = blockIdx.x * output_suze + threadIdx.x - filter_r;\n    int out_y = blockIdx.y * output_suze + threadIdx.y - filter_r;\n\n    int out_ch = blockIdx.z;\n\n    extern __shared__ float cell[];\n\n    // In and Out data dimensions:\n    // 0 - channel\n    // 1 - height\n    // 2 - width\n\n    // Filter dimensions:\n    // 0 - out channels\n    // 1 - in channels\n    // 2 - height\n    // 3 - width\n\n#ifdef SINGLE_BLOCK\n    int blockId = blockIdx.z * gridDim.y * gridDim.x + blockIdx.y * gridDim.x + blockIdx.x;\n\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        while (atomicAdd(debug_counter, 0) != blockId) {\n        }\n    }\n    __syncthreads();  // This is needed because only the first thread of the block is watinig for\n                      // the blocks turn to run\n\n#endif\n\n#ifdef DEBUG\n    if (!threadIdx.x && !threadIdx.y && !blockIdx.x && !blockIdx.y && !blockIdx.z) {\n        PRINT_INPUTS();\n    }\n#endif\n\n    // Loop over the output channels\n\n    // // Pointer to the 2d slice of the output\n\n    float *sub_output = out + out_ch * w * h;\n    ACCUM_DTYPE R = 0;\n    // Loop over the input channels\n    for (int in_c = 0; in_c &lt; in_channels; in_c++) {\n        // Pointer to the 2d slice of the filter that corresponds to the active input and output\n        // channels\n        float *sub_filter = filter + (filter_size * filter_size * in_channels * out_ch) +\n                            (filter_size * filter_size * in_c);\n        // Pinter to the current channel in the input\n        float *sub_input = in + (w * h * in_c);\n\n        if (out_x &gt;= 0 && out_y &gt;= 0 && out_x &lt; w && out_y &lt; h) {\n            cell[threadIdx.y * TILE_SIZE + threadIdx.x] = sub_input[(out_y)*w + out_x];\n        } else {\n            cell[threadIdx.y * TILE_SIZE + threadIdx.x] = pad;\n        }\n        __syncthreads();  // Wait for all threads to load the input\n\n#ifdef DEBUG\n        if (!threadIdx.x && !threadIdx.y) {\n            printf(\"Cell contents at (%d, %d, %d):\\n\", blockIdx.z, blockIdx.y, blockIdx.x);\n            print_data_float(cell, h, w);\n        }\n#endif\n\n        // Apply the filter to the cell, which should be padded if it lands outside of the input.\n\n        if (threadIdx.x &gt;= filter_r && threadIdx.x &lt; TILE_SIZE - filter_r &&\n            threadIdx.y &gt;= filter_r && threadIdx.y &lt; TILE_SIZE - filter_r) {\n            for (int filter_y = 0; filter_y &lt; filter_size; filter_y++) {\n                for (int filter_x = 0; filter_x &lt; filter_size; filter_x++) {\n                    R += cell[(threadIdx.y + filter_y - filter_r) * TILE_SIZE +\n                              (threadIdx.x + filter_x - filter_r)] *\n                         sub_filter[filter_y * filter_size + filter_x];\n                }\n            }\n        }\n\n        __syncthreads();  // Wait for all threads to complete before we load the next input\n    }\n    if ((threadIdx.x &gt;= filter_r && threadIdx.x &lt; TILE_SIZE - filter_r) &&\n        (out_x &gt;= 0 && out_x &lt; w) &&\n        (threadIdx.y &gt;= filter_r && threadIdx.y &lt; TILE_SIZE - filter_r) &&\n        (out_y &gt;= 0 && out_y &lt; h)) {\n        sub_output[(out_y)*w + out_x] = R;\n    }\n\n#ifdef SINGLE_BLOCK\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        atomicAdd(debug_counter, 1);\n    }\n#endif\n}\n\n\nfrom typing import Optional\n\n\ndef benchmark_conv2d_pad(\n    kernel,\n    block_size: tuple[int],\n    grid_size: tuple[int],\n    shared_mem_size: Optional[int],\n    input: np.array,\n    filter: np.array,\n    repeat: int = 5,\n    verbose=False\n):\n    # input, channel-first\n    # - Channel\n    # - Height\n    # - Width\n    assert len(input.shape) == 3\n\n    # Filter shape should be\n    # - Out channels\n    # - In  channels\n    # - Height\n    # - Width\n    assert len(filter.shape) == 4\n\n    in_ch, h, w = input.shape\n    out_ch, in_ch2, fh, fw = filter.shape\n\n    assert fh == fw, f\"Only square filters supported, got shape={filter.shape}\"\n    assert in_ch == in_ch2\n\n    out_shape = (out_ch, h, w)\n    pad = 0\n\n    if verbose:\n        print(f\"Input shape: {input.shape}\")\n        print(f\"Filter shape: {filter.shape}\")\n        print(f\"Result shape: {out_shape}\")\n        print(f\"Grid size: {grid_size}\")\n        print(f\"Block size: {block_size}\")\n        print(f\"Shared memory size: {shared_mem_size}\")\n        print(f\"Total threads: {prod((*grid_size, *block_size))}\")\n\n    gpu_input = cuda.mem_alloc_like(input)\n    gpu_filter = cuda.mem_alloc_like(filter)\n\n    out = np.empty(out_shape, dtype=np.float32)\n\n    cuda.memcpy_htod(gpu_input, input)\n    cuda.memcpy_htod(gpu_filter, filter)\n\n    cuda.Context.synchronize()\n\n    timing = 0\n\n    for _ in range(repeat):\n        start = cuda.Event()\n        end = cuda.Event()\n\n        gpu_out = cuda.mem_alloc_like(out)\n\n        cuda.Context.synchronize()\n        start.record()\n\n        shared_kwarg = {}\n        if shared_mem_size is not None:\n            shared_kwarg = {\"shared\": shared_mem_size}\n\n        kernel(\n            gpu_input,\n            gpu_out,\n            gpu_filter,\n            np.int32(h),\n            np.int32(w),\n            np.int32(in_ch),\n            np.int32(out_ch),\n            np.int32(fh),\n            np.float32(pad),\n            grid=grid_size,\n            block=block_size,\n            **shared_kwarg\n        )\n        end.record()\n        end.synchronize()\n\n        timing += end.time_since(start)\n    timing /= repeat\n\n    cuda.memcpy_dtoh(out, gpu_out)\n    cuda.Context.synchronize()\n    return out, timing\n\n\ndef benchmark_conv2d_pad_z_out_shared_halo(kernel, input: np.array, filter: np.array, tile_size: int, **kwargs):\n    in_ch, h, w = input.shape\n    out_ch, in_ch2, fh, fw = filter.shape\n\n    assert fh == fw\n\n    output_tile_size = tile_size - fw + 1\n\n    block_size = (tile_size, tile_size, 1)\n    grid_size = (((w+output_tile_size-1) // output_tile_size), ((h+output_tile_size-1) // output_tile_size), out_ch)\n    shared = (output_tile_size+fw) * (output_tile_size+fh) * 4\n\n    return benchmark_conv2d_pad(\n        kernel=kernel, input=input, filter=filter, block_size=block_size, grid_size=grid_size, shared_mem_size=shared, **kwargs\n    )\n\n\ndef benchmark_conv2d_pad_naive(kernel, input: np.array, filter: np.array, tile_width, **kwargs):\n    in_ch, h, w = input.shape\n    out_ch, in_ch2, fh, fw = filter.shape\n\n    block_size = (tile_width, tile_width, 1)\n    grid_size = (((w+tile_width-1) // tile_width), ((h+tile_width-1) // tile_width), 1)\n\n    return benchmark_conv2d_pad(kernel=kernel, input=input, filter=filter, block_size=block_size, grid_size=grid_size, **kwargs)\n\n\nin_chan_range = [1, 3, 8, 32, 128, 512]\nout_chan_range = [1, 4, 8, 32, 128, 512]\n\nfilter_size = [1, 3, 5, 9]\n\nimg_size_range = [64, 128, 256, 512, 1024]\n\n# Let's sample from the available options.\nn_samples = 50\n\n# Generate all possible combinations\ncombinations = []\nfor in_ch in in_chan_range:\n    for out_ch in out_chan_range:\n        for fs in filter_size:\n            for img_size in img_size_range:\n                n = in_ch * out_ch * img_size * img_size\n\n                # Skip combinatoins that are too large\n                if n &lt; 1024 * 1024 * 32 * 32:\n                    combinations.append((in_ch, out_ch, fs, img_size))\n\nn_samples = min(n_samples, len(combinations))\nsampled_combinations = np.random.choice(len(combinations), size=n_samples, replace=False)\ntest_cases = [combinations[i] for i in sampled_combinations]\n\n\n\nUsing double for accumulator\nI’ve noticed that we get a lot less discrepency between torch and my implementation when using a double for accumulator. Let’s benchmark the two.\n\ntile_size = 16\n\n# test_cases = [(512, 128, 9, 64)]\n\n\n# + [\"-DDEBUG=1\"],\nmod = SourceModule(\n    Path(cu_file).read_text(),\n    options=warn_options.warn_options + [\"-DACCUM_DTYPE=float\", f\"-DTILE_SIZE={tile_size}\"],\n    include_dirs=[str(Path(\"./kernels/conv2d/\").absolute())]\n)\nmod_double = SourceModule(\n    Path(cu_file).read_text(),\n    options=warn_options.warn_options + [\"-DACCUM_DTYPE=double\", f\"-DTILE_SIZE={tile_size}\"],\n    include_dirs=[str(Path(\"./kernels/conv2d/\").absolute())]\n)\n\nbenchmarks = {\n    \"conv2d_pad_z_out_shared_halo_float\": (\n        benchmark_conv2d_pad_z_out_shared_halo,\n        mod.get_function(\"conv2d_pad_z_out_shared_halo\")\n        ),\n    \"conv2d_pad_z_out_shared_halo_double\": (\n        benchmark_conv2d_pad_z_out_shared_halo,\n        mod_double.get_function(\"conv2d_pad_z_out_shared_halo\")\n        )\n}\n\ndef run_benchmarks(benchmarks, test_cases):\n    data = []\n\n    for tc in tqdm(test_cases):\n        ch_in, ch_out, fs, pixels = tc\n\n        array_in = np.random.randn(ch_in, pixels, pixels).astype(np.float32)\n        filter = np.random.randn(ch_out, ch_in, fs, fs).astype(np.float32)\n\n\n        torch_out = conv2d(Tensor(array_in), Tensor(filter), padding=\"same\")\n\n        timings = {}\n\n        for benchmark_name, (benchmark_func, kernel) in benchmarks.items():\n            res, timing = benchmark_func(kernel, input=array_in, filter=filter, tile_size=tile_size, repeat=5)\n\n            similarity = float(np.isclose(res, torch_out, atol=1e-04, rtol=1e-4).mean())\n            if similarity &lt; 0.9:\n                print(f\"## Mismatch for '{benchmark_name}\")\n                print(f\"In: {array_in.shape}\")\n                print(f\"Out: {(ch_out, pixels, pixels)}\")\n                print(f\"Filter: {filter.shape}\")\n                print(f\"Similarity: {similarity}\")\n\n                # display(Lo(np.isclose(res, torch_out,  atol=1e-04, rtol=1e-4)).chans(cl=False, scale=2))\n                # raise Exception\n\n            timings[benchmark_name] = timing\n            # time.sleep(10)\n\n        cuda.Context.synchronize()\n\n        data.append({\n            'in_ch': ch_in,\n            'out_ch': ch_out,\n            'filter_size': fs,\n            'img_size': pixels,\n            # 'kernel': kernel_name,\n        } | timings)\n\n    return pd.DataFrame(data)\n\n\nresults = run_benchmarks(benchmarks, test_cases)\n\n\n\n\n\n\nResults\n\ndef plot_results(results, sort_column: str, timing_columns: list[str]):\n\n    # Sort by conv2d_pad timing\n    results_sorted = results.sort_values(by=sort_column)\n\n    # Create a plot comparing the two kernels\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n\n    # Create labels for x-axis that include dimensions\n    results_sorted['dimensions'] = results_sorted.apply(\n        lambda row:\n        f\"{int(row['img_size'])}×{int(row['img_size'])}×{int(row['in_ch'])} -&gt; \" +\n        f\"{int(row['out_ch'])}, f:{int(row['filter_size'])}×{int(row['filter_size'])}\",\n        axis=1\n    )\n\n    # Melt the dataframe to get it in the right format for seaborn\n    melted_results = pd.melt(\n        results_sorted,\n        id_vars=['in_ch', 'out_ch', 'filter_size', 'img_size', 'dimensions'],\n        value_vars=timing_columns,\n        var_name='kernel',\n        value_name='time'\n    )\n\n    # Split the data into two halves based on timing\n    midpoint = len(results_sorted) // 2\n    faster_results = melted_results[melted_results['dimensions'].isin(results_sorted['dimensions'][:midpoint])]\n    slower_results = melted_results[melted_results['dimensions'].isin(results_sorted['dimensions'][midpoint:])]\n\n    # Create a figure with two subplots\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n\n    # Plot faster results in the first subplot\n    sns.barplot(x='dimensions', y='time', hue='kernel', data=faster_results, ax=ax1)\n    ax1.set_xlabel('')\n    ax1.set_ylabel('Time (ms)')\n    ax1.set_title('Performance Comparison - Faster Results')\n    ax1.tick_params(axis='x', rotation=90)\n    ax1.legend(title='Kernel')\n\n    # Plot slower results in the second subplot\n    sns.barplot(x='dimensions', y='time', hue='kernel', data=slower_results, ax=ax2)\n    ax2.set_xlabel('Input and Filter Dimensions')\n    ax2.set_ylabel('Time (ms)')\n    ax2.set_title('Performance Comparison - Slower Results')\n    ax2.tick_params(axis='x', rotation=90)\n    ax2.legend(title='Kernel')\n\n    # Adjust layout\n    plt.tight_layout()\n    plt.show()\n\nplot_results(results,\n             \"conv2d_pad_z_out_shared_halo_float\",\n             [\"conv2d_pad_z_out_shared_halo_float\", \"conv2d_pad_z_out_shared_halo_double\"])\n\n# Also display the sorted results table\n# results_sorted\n\n\n\n\n\n\n\n\nOk, double is slow AF. I guess I’ll stick to the float accumulator. We will compare all the kernels to date tomorrow.",
    "crumbs": [
      "Day 12 - conv2d with shared memory and halo"
    ]
  }
]